{"meta":{"title":"Jiacan‘s Blog","subtitle":null,"description":null,"author":"Jiacan Liao","url":"http://liaojiacan.me"},"pages":[{"title":"分类","date":"2019-05-22T05:43:18.862Z","updated":"2019-05-22T05:43:18.862Z","comments":false,"path":"categories/index.html","permalink":"http://liaojiacan.me/categories/index.html","excerpt":"","text":""},{"title":"分类","date":"2019-05-22T05:43:18.866Z","updated":"2019-05-22T05:43:18.866Z","comments":false,"path":"tags/index.html","permalink":"http://liaojiacan.me/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"【高可用架构】理解有状态服务和无状态服务？","slug":"【高可用架构】理解有状态服务和无状态服务","date":"2019-05-27T08:41:14.000Z","updated":"2019-05-27T11:07:19.572Z","comments":true,"path":"2019/05/27/【高可用架构】理解有状态服务和无状态服务/","link":"","permalink":"http://liaojiacan.me/2019/05/27/【高可用架构】理解有状态服务和无状态服务/","excerpt":"","text":"前言 “有状态&quot;和&quot;无状态” 这个两词经常会出现在一些架构设计的文章中，怎么去理解这两个的含义？这2种场景下该如何做高可用，数据一致性怎么解决？ 正文 对于&quot;状态&quot;我个人的理解是， 对于同一时刻同一个请求产生的数据的状态数为一的则为无状态，大于一则认为有状态，至于是否允许多状态共存，取决于对一致性的要求。 从数据层面看状态 数据的状态往往受2个纬度有关，一是与时间相关或者顺序相关的，不同的操作顺序可能导致同一个时间点上的数据状态&gt; 1个，二是与数据的副本状态相关的，数据落在多个副本上，可能出现多种数据状态的组合。 时间状态： 操作顺序有一定的限制，同一个状态的数据不能出现在2个时间点（重复请求）。 如有个数据新增 ，更新，删除这3个顺序的请求，在下游业务也需要同样的顺序操作。 对于单状态的数据，如计数器，不能出现重复添加，也就是这个数据只有第一次出现的时间状态是对的，后来的数据在时间状态上是不允许的，对于这种场景，往往通过把这个&quot;点&quot;状的数据，换成&quot;线&quot;数据，比如换把计数器记录成操作历史，这个点的状态由这些历史数据聚合而成，&quot;线”数据容易做幂等操作。 位置状态 : 数据落地点的状态。 数据拆分后的应用，同一个数据就有了状态，他只能落在指定的节点上。 对于复制集架构，数据是存在多个副本的，也就是说数据落在的位置在集群上需要有一定的数量保证，以满足一定的共识基础，比如要写半数以上节点，也就是说这个数据是存在2个状态的，对于已经写成功的节点是成功状态，对于未写成功的节点是未成功/处理中的状态。如何协调这些状态，往往要引入一些共识协议（Paxos，Raft）。 从服务层面看状态 服务层面的状态取决于实例是单独维护数据还是共享数据，或者说是否存在多个数据闭环让数据的流向产生了多条路径。有状态的服务往往比较难进行水平拓展，在现在容器盛行的环境，把服务设计成无状态的更加高效，即便是有状态的服务，也要将状态内敛在系统的某个范围，比如分布式的存储，对于业务服务，我不需要关系数据在多个副本的状态，数据的状态由分布式存储这个服务本身解决。 有状态服务 服务本身依赖或者存在局部的状态数据，这些数据需要自身持久化或者可以通过其他节点恢复。 一个请求只能被某个节点（或者同等状态下的节点）处理。 存储状态数据，实例的拓展需要整个系统参与状态的迁移。 在一个封闭的系统中，存在多个数据闭环，需要考虑这些闭环的数据一致性问题。 通常存在于分布式架构中。 无状态服务 服务不依赖自身的状态，实例的状态数据可以维护在内存中。 任何一个请求都可以被任意一个实例处理。 不存储状态数据，实例可以水平拓展，通过负载均衡将请求分发到各个节点。 在一个封闭的系统中，只存在一个数据闭环。 通常存在于单体架构的集群中。 怎么做转换 采用复制或者集中式消除数据状态。 对于Web服务，如果数据存在session中，那么这个服务就有了状态。 一种是对session进行复制，同步复制还是异步复制，取决于你对数据一致性的敏感程度。 也可以将session集中式管理，如用redis，出现性能或者容量的瓶颈，再换分布式的缓存，把状态交于缓存服务维护。 我们可以看出，有状态的服务，它的数据是存在多个闭环的，比如Web01-session-01-&gt; DB 和 Web02-session-&gt;DB 。通过复制，将session-01 和 02 等同于同一个。 或者我们可以将数据进行分区，让负载均衡器通过hash算法将请求落在固定的处理节点上。 采用控制节点来保证集中式存储的高可用和一致性。 在高可用的架构下，数据往往得存在多副本（鸡蛋别放一个篮子里面） CAP理论，C和A不可能同时满足，多副本的存在让A可在有限时间内恢复，而C可用采用Quorum 机制来控制多个副本节点的数据一致性问题，保证半数以上的节点的写成功。","categories":[{"name":"高可用架构","slug":"高可用架构","permalink":"http://liaojiacan.me/categories/高可用架构/"}],"tags":[{"name":"系统设计","slug":"系统设计","permalink":"http://liaojiacan.me/tags/系统设计/"},{"name":"架构设计","slug":"架构设计","permalink":"http://liaojiacan.me/tags/架构设计/"},{"name":"分布式","slug":"分布式","permalink":"http://liaojiacan.me/tags/分布式/"},{"name":"高可用","slug":"高可用","permalink":"http://liaojiacan.me/tags/高可用/"}]},{"title":"【系统与架构设计】你知道硬盘能有多快吗？","slug":"【系统与架构设计】你知道硬盘能有多快吗","date":"2019-05-22T08:40:14.000Z","updated":"2019-05-22T11:05:37.070Z","comments":true,"path":"2019/05/22/【系统与架构设计】你知道硬盘能有多快吗/","link":"","permalink":"http://liaojiacan.me/2019/05/22/【系统与架构设计】你知道硬盘能有多快吗/","excerpt":"","text":"应用软件通常都是由各种类型的软硬件相互配合实现，无论你是单体架构还是分布式架构，任何一个模块或者环节都可能是系统的瓶颈，可能是CPU，可能是网络，也可能是硬盘等。了解一些基础的边界（“量”），有助于我们分析系统的瓶颈。 问题 大部分的应用系统都是IO密集型，同机房的服务一般性能的瓶颈在于磁盘IO，那么一般机械硬盘的性能上限是怎么样的，根据磁盘的最大性能能否判断我们的系统是否有优化的空间？ B+ tree 的索引 一般是3～4层，也就是平均情况下需要3到4次的I/O，我们的应用需要1000TPS，普通的机械磁盘的性能是否能达到要求？ 假如innodb的事务处理能力只受redo log 的写入速度影响，一条操作日志1kb的话，TPS可以到达多少？ 假如网络带宽限制不计的话，我们从一台机器同步一个1TB的数据，机械硬盘需要多久？ 这些问题可能都不是正确的问题，我想表达的是假如现在来解答这些问题，能否根据自己的一些印象（磁盘的性能的量级。HDD硬盘100MB/s，SSD 500MB/s ，IOPS 100… 等）来估算一下。 存储设备的2个性能指标 IOPS ：(Input/Output Per Second) 每秒的输入输出量，代表存储系统的每秒的I/O请求数。“只关系数量” Random Read IOPS(随机读) Random Write IOPS(随机写) Sequential Read IOPS(顺序读) Sequential Write IOPS(顺序写) Total IOPS （混合读写） 带宽/吞吐量：单位时间内传输的数据大小，比如10MB/秒 。“只关系比特数或者说容量” 对于OLTP应用/数据库，我们看重的更多的是随机I/O的性能，这个时候看IOPS更加合理，对于大文件或者顺序读写的应用（hadoop/kafka……），更加看重的是吞吐量。 机械硬盘 HDD IOPS ：100左右 设备 形式 IOPS 接口 注解 7,200RPMSATA硬盘驱动器 硬盘驱动器 ~75-100 IOPS SATA 3Gbit/s 10,000 RPM SATA硬盘驱动器 硬盘驱动器 ~125-150 IOPS SATA 3 Gbit/s 10,000 rpmSAS硬盘驱动器 硬盘驱动器 ~140 IOPS SAS（串列SCSI） 15,000 rpmSAS硬盘驱动器 硬盘驱动器 ~175-210 IOPS SAS（串列SCSI） 数据来源于百度百科 https://baike.baidu.com/item/IOPS 带宽/吞吐量 ：100MB/s 左右 数据来源 https://hdd.userbenchmark.com/ 可以看到 机械硬盘的的读写速度在 ～20.6MB/s - 200MB/S 之间 固态硬盘 SSD IOPS ：8000～80000 设备 形式 IOPS 接口 注解 英特尔Intel X25-M G2（MLC） SSD ~8,600 IOPS SATA 3 Gbit/s 英特尔的数据表声称在4KB数据的写入及读取时，分别有有6,600/8,600 IOPS (80GB/160GB版本)及35,000 IOPS的速度。 英特尔 Intel X25-E (SLC) SSD ~5,000 IOPS SATA 3 Gbit/s 英特尔数据表声称在写入和读取的速度为3,300 IOPS及35,000 IOPS。写入和读取混和时为5,000 IOPS。英特尔的X25-E G1比X25-M G2快了约三倍 G.SkillPhoenix Pro SSD ~20,000 IOPS。 SATA 3 Gbit/s SandForce-1200为基础的固态硬件，配合加强版的固件，最快可到50,000 IOPS，性能测试的结果是随机读取可到~25,000 IOPS，随机写入可到~15,000 IOPS。 OCZVertex 3 SSD 最高可到60,000 IOPS SATA 6 Gbit/s 随机写入4KB (Aligned) CorsairForce Series GT SSD 最高可到85,000 IOPS SATA 6 Gbit/s 240GB Drive，循序读取为555 MB/s，循序写入为525 MB/s。随机写入4KB (Aligned) 数据来源于百度百科 https://baike.baidu.com/item/IOPS 带宽/吞吐量： 读548MB/S | 写 370MB/s 数据来源 https://ssd.userbenchmark.com/","categories":[{"name":"系统与架构设计","slug":"系统与架构设计","permalink":"http://liaojiacan.me/categories/系统与架构设计/"}],"tags":[{"name":"系统设计","slug":"系统设计","permalink":"http://liaojiacan.me/tags/系统设计/"},{"name":"架构设计","slug":"架构设计","permalink":"http://liaojiacan.me/tags/架构设计/"},{"name":"存储","slug":"存储","permalink":"http://liaojiacan.me/tags/存储/"}]},{"title":"一种适合后端团队代码的GIT分支管理办法","slug":"一种适合后端代码的GIT分支管理办法","date":"2019-05-21T08:45:44.000Z","updated":"2019-05-22T05:43:18.860Z","comments":true,"path":"2019/05/21/一种适合后端代码的GIT分支管理办法/","link":"","permalink":"http://liaojiacan.me/2019/05/21/一种适合后端代码的GIT分支管理办法/","excerpt":"","text":"每个公司甚至公司中的不同团队对代码的分支管理都是有所差别，网上也有很多人分享了他们的分支管理规范，相信很多有一种感觉就是采用了他们的方法然后真正实践起来总是有些水土不服，我个人认为分支的管理需要结合团队规模、应用类型、发布流程等实际的情况来制定规范。下面我将介绍一种适用于后端开发团队且做toC产品业务后台的代码分支管理办法。 不同业务代码的管理需求差异 业务后台 基础工具SDK/中间件 独立部署企业软件 多版本 不需要 需要 需要 迭代频率 1-2周 少更新 少更新 更新方式 灰度更新 更新SDK版本号 补丁包更新，不同版本不同的补丁包 维护版本 最近的2个版本，主要是发布失败会滚用 每个release版本都需要单独维护 每个客户的版本都要单独维护 从上面的对比结果看，在做to C 产品的业务后台的，相对于开源软件，企业软件，中间件等对于版本控制的生命周期没有那么长，不需要对每个release版本进行长时间的维护跟踪，我们的服务更新永远只有一条线，因为我们的服务面向的研发只有自己的团队，就算出现版本兼容，在随后的几个版本也能快速升级上来。需要做好版本控制的仅仅在于最近上线的几个版本中。 一种适合业务后台开发的GIT分支管理模型 develop： 开发分支，平常开发的代码都提交到这里，为了简化，这里可以不用根据版本号进行细化分支。 feature/xxx: 特性分支，这个目录下的分支，用于开发一些新特性，或者说是最近不需要上线的功能。 stage： 测试分支，这个分支代表测试环境的代码，测试环境的镜像/程序必须通过该分支来构建，保证测试结果与代码的一致性。 master：生产分支，这个分支代表生产环境的代码，生产环境的镜像/程序必须通过该分支来构建，部署后打tag确定release版本，对应我们的场景(业务后台)，我们只需要维护最近的2个release版本，一般情况下只能回滚最近的版本。 bugfix-xx: 补丁分支，这个是一个临时分支，从待修复版本的起点开分支，每个分支对应一个补丁程序，在本地验证后，需要把补丁合并到stage进行测试验证，验证通过后再将补丁合并到master进行修复，同样也需要把补丁打到develop。 工作中常见的场景 开发周期中，所有的功能在当前周期都能完成，需求评审确认通过且开发任务符合预期： 时间线：D1→D2→D3→D4→S3→M2 。因为经过评估在下一个发布时间前开发人员能够将D1到D4的4个功能完成开发，所以在次期间我们只需要保证这个分支的功能能正常演进即可，尽量不要引进太多的分支。 开发周期中，所有功能在当前周期完成，需求评审确认通过，少部分功能上线时间待定，任务进度符合预期： 这个时候可能存在2条线，大部分人参与当前版本的功能开发（develop分支的演进），少部分人进行未来版本上线的需求开发（F1，F2，F3）。F3→S2 这个合并尽量等到需求拍定上线版本后合并到stage给测试人员测试。 线上BUG的修复： 确认BUG后，如果是测试人员反馈回来的一般会是在JIRA 上提单，我们可以根据jira的issue Id，在master 上 创建一个bugfix-jira-xx，接下来在这个分支上完成补丁的开发（B1→B2），之后合并补丁到stage分支进行测试环境的部署（B2→S4），等待测试人员的验证，验证完成后将补丁合并到master和develop分支（B2→M3，B2→D5），并打一个小版本号的tag。 有个新功能，老板想立马上线，但是发版的时间还没到： 这种情况，把这个功能当成一个超前的feature处理，我们上面说的feature是一个未来版本的功能，可以走未来版本的测试上线流程，这里的feature 是一个超前的功能，我们需要走类似bugfix的流程，进行一个快速的开发上线。 如果你们有遇到比较棘手的分支管理问题，欢迎留言交流。","categories":[{"name":"开发规范","slug":"开发规范","permalink":"http://liaojiacan.me/categories/开发规范/"}],"tags":[{"name":"开发规范","slug":"开发规范","permalink":"http://liaojiacan.me/tags/开发规范/"},{"name":"代码管理","slug":"代码管理","permalink":"http://liaojiacan.me/tags/代码管理/"},{"name":"GIT","slug":"GIT","permalink":"http://liaojiacan.me/tags/GIT/"}]},{"title":"自定义ClassLoader实现一个支持热加载的应用启动器","slug":"自定义ClassLoader实现一个支持热加载的应用启动器","date":"2019-03-17T08:46:00.000Z","updated":"2019-05-22T05:43:18.861Z","comments":true,"path":"2019/03/17/自定义ClassLoader实现一个支持热加载的应用启动器/","link":"","permalink":"http://liaojiacan.me/2019/03/17/自定义ClassLoader实现一个支持热加载的应用启动器/","excerpt":"","text":"JVM 默认是不支持Class的热加载的，也就是说我们的代码有变动，就要重启JVM来达到加载新的Class目的，但是很多容器如Tomcat、Jetty等都可以支持热加载，其底层的原理就是自定义ClassLoader。OSGI更是将类加载器玩到极至。我们来看看怎么实现一个简单的支持热加载的应用启动器。 一、实现的目标 支持热加载 可配置的启动类 二、实现 1. 支持热加载 关于类的加载，必然要说一下ClassLoader，JDK中存在这几个ClassLoader： BootstrapClassLoader 加载基础类 ExtClassLoader 加载拓展类，父加载器是BootstrapClassLoader AppClassLoader 加载应用程序类 ，父加载器是ExtClassLoader 双亲委派： 官方建议开发者，实现类加载器时遵循双亲委派规则，就是加载一个类时，先交给父加载器加载，如果父加载器无法加载，再由当前类加载器加载，从代码上来说，AppClassLoader已经写好了这个模版类，我们只需要覆盖findClass的逻辑即可。 实现热加载需要违背双亲委派规则吗？ 由于ClassLoader中的defineClass方法会对已加载的类进行校验，所以我们无法对一个类进行重复加载，要实现热加载只能创建一个新的ClassLoader，假如我们采用双亲委派规则，那么我们需要加载的类会先被父加载器（AppClassLoader）给加载缓存起来，之后我们无论怎么创建一个新的加载器也无法达到热加载的目的。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public class HotSwapClassLoader extends ClassLoader &#123; /** * 指定目录下的类可以热加载 */ private String basePath; public HotSwapClassLoader(String basePath) &#123; this.basePath = basePath; &#125; @Override public Class&lt;?&gt; loadClass(String name) throws ClassNotFoundException &#123; Class&lt;?&gt; c = findLoadedClass(name); // 加载指定目录下的class if (c == null) &#123; try &#123; c = findClass(name); if (c != null) &#123; return c; &#125; &#125; catch (ClassNotFoundException e) &#123; return super.loadClass(name); &#125; &#125; return super.loadClass(name); &#125; @Override protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; String classResourcePath = this.basePath + &quot;/&quot; + name.replaceAll(&quot;\\\\.&quot;, &quot;/&quot;); try &#123; FileInputStream fileInputStream = new FileInputStream(new File(classResourcePath)); ByteArrayOutputStream byteArrayOutputStream = new ByteArrayOutputStream(); int len; byte[] buffer = new byte[1024]; while ((len = fileInputStream.read(buffer)) &gt; 0) &#123; byteArrayOutputStream.write(buffer, 0, len); &#125; byte[] bytes = byteArrayOutputStream.toByteArray(); return defineClass(name, bytes, 0, bytes.length); &#125; catch (IOException e) &#123; throw new ClassNotFoundException(name); &#125; &#125;&#125; 2. 启动器 上面我们已经实现了一个可以随时替换的ClassLoader，我们还需要一个引导类去维护我们的ClassLoader 还有我们的应用启动入口，管理启动和关闭的时机，就好比Tomcat的Catalina一样，或者说我们的任何类的Main函数。 123456789101112131415161718192021public class Bootstrap &#123; private String basePath; private Object application; private String applicationClassName; private volatile ClassLoader applicationClassLoader; public Bootstrap(String basePath, String applicationClassName) &#123; this.basePath = basePath; this.applicationClassLoader = new HotSwapClassLoader(this.basePath); this.applicationClassName = applicationClassName; try &#123; this.application = getApplication(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125; 有了上面的那些成员，我们就可以利用Java的反射来实现自定义的Application类的启动（这个类可以方在任意位置，就好比我们的war包可以方在任意位置，只要在tomcat的server.xml中配置好baseApps的路径就好了） 1234567private void startApplication() throws NoSuchMethodException, InvocationTargetException, IllegalAccessException &#123; this.application.getClass().getDeclaredMethod(&quot;start&quot;, null).invoke(this.application, new Object[0]);&#125;private void stopApplication() throws NoSuchMethodException, InvocationTargetException, IllegalAccessException &#123; this.application.getClass().getDeclaredMethod(&quot;stop&quot;, null).invoke(this.application, new Object[0]);&#125; 最后，剩下最后一个问题就是，我们怎么知道我们的类需要加载呢？有2种方式就是主动刷新，还有一种就是程序监听文件夹的文件变动。我们可以利用jdk7之后提供的WatchService来监控文件或者目录的变动情况，一发生变动，则先注销之前的Application 然后再创建一个新的HotSwapClassLoader来启动新的Application。 1234567891011121314151617private void registerResourceWatcher() &#123; try &#123; WatchService watchService = FileSystems.getDefault().newWatchService(); Path p = Paths.get(basePath); p.register(watchService, new WatchEvent.Kind[]&#123;ENTRY_MODIFY, ENTRY_CREATE, ENTRY_DELETE&#125;); while (true) &#123; WatchKey k = watchService.take(); for (WatchEvent&lt;?&gt; e : k.pollEvents()) &#123; reloadApplication(); break; &#125; k.reset(); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; 三、测试 123456789101112131415161718public class Application &#123; public Integer version = 46; /** * 应用的启动入口 */ public void start() &#123; System.out.println(&quot;Start... version=&quot; + version); &#125; /** * 应用的停止入口 */ public void stop() &#123; System.out.println(&quot;Stop... version=&quot; + version); &#125;&#125; 12345678public class Main &#123; public static void main(String[] args) throws IOException, InterruptedException &#123; new Bootstrap(&quot;/Users/liaojiacan/Workspace/java/personal/code-snippets/java-language/target/classes&quot; ,&quot;com.github.liaojiacan.classloader.app.Application&quot;).boot(); &#125;&#125; 启动后，我们修改Application的 version=47，然后rebuild project，这个时候这个文件就会发生改变,输出如下： 123Start... version=46Stop... version=46Start... version=47 完整代码见Github :https://github.com/liaojiacan/code-snippets/tree/master/java-language/src/main/java/com/github/liaojiacan/classloader","categories":[{"name":"JDK","slug":"JDK","permalink":"http://liaojiacan.me/categories/JDK/"}],"tags":[{"name":"ClassLoader","slug":"ClassLoader","permalink":"http://liaojiacan.me/tags/ClassLoader/"},{"name":"热加载","slug":"热加载","permalink":"http://liaojiacan.me/tags/热加载/"}]},{"title":"Java中的多线程和锁实现原理","slug":"Java中的多线程和锁实现原理","date":"2019-03-11T09:19:00.000Z","updated":"2019-05-22T05:43:18.857Z","comments":true,"path":"2019/03/11/Java中的多线程和锁实现原理/","link":"","permalink":"http://liaojiacan.me/2019/03/11/Java中的多线程和锁实现原理/","excerpt":"","text":"线程的实现 Java 规范里面并没有规定JVM要如何实现线程模型，在HotSpot VM 中使用的是1:1的线程模型，即1个java线程对应一个OS的线程（内核线程），在Thread中又很多native方法，就是调用OS的函数进行用户线程和内核线程的绑定。 每个线程都又一个内核线程与之绑定，用户线程推出，内核线程也会一起退出。 内核线程的数量是有限制的 内核线程调用，上下文切换开销很大。 线程调度 线程的状态 （Thread.State枚举） NEW : RUNNABLE : 对应的就绪和运行态 BLOCKED : 阻塞状态，处于阻塞状态的线程会不断地请求资源，请求成功后就会进入就绪状态。 WAITING : 等待状态，当线程调用wait,join,park等函数。等待状态下会释放资源，让出CPU和释放锁。需要其他线程唤醒。 TIMED_WAITING 有限的等待。 TERMINATED 线程相关的一些文章 Java的线程管理器能保证每个线程都有执行的机会么? wait/notify实现原理 锁 因为多线程的共享数据存在线程安全问题，需要通过一些控制来保证共享数据的读写，JVM层面提供sychronized的锁，而java层面current包下面有许多基于AQS的Lock的实现,在jdk1.6后,synchronized 和 ReentrantLock性能上以及没有太大的差距，ReentrantLock的使用更佳灵活，性能稳定，支持超时机制等，而采用synchronized不需要程序自己控制锁的加锁和释放，不容易出现死锁等问题。 synchronized 的实现原理 JVM规范规定基于进入和退出monitor对象来控制方法和代码块的同步，也是就是monitorenter和monitorexit两个指令，当程序执行到monitorenter指令时会尝试获取对象的monitor所有权，也就是获取对象的锁。在最开始的JVM实现中是采用重量级锁的实现，线程的切换都涉及到用户态到内核态的切换，比较消化资源，所以在jdk1.6对锁进行优化。 同步原理 JVM是怎么控制多线程程序的交替访问的？ Java中每个对象都有一个内置锁与之对应，所有需要对该对象进行排他性或者一致性访问时需要获取对象的内置锁（synchronized 中的代码，monitorenter指令）。这个内置锁的信息存在对象的对象头中（一些基本信息，其他的condition，队列等是在native heap中的）。一个对象的Monitor只能被一个线程获取到，其他线程得等待持有的Monitor的线程释放。 在一些官方的注释中说的是ObjectMonitor是一个内联锁对象的封装，就好比JVM层面实现的一个类似JUC框架下的Lock（不是说ObjectMonitor是JUC的Lock实现，说的是他们可能实现思路是一样的）。 做好线程的同步协调，我认为需要这3样东西（ObjectMonitor 和J.U.C的AQS 都是这样的）： 维护一个竞争的互斥量 一个队列 线程的挂起和唤醒 实现同步也可以只用一个互斥量，自旋锁就是这么实现的，但是锁竞争太激烈会导致CPU做无用功。 想继续了解ObjectMonitor的实现可以看这几篇文章： synchronized 与 object’s Monitor Moniter实现原理 对象头 Object的锁信息是存在在哪里的？ 在获取对象的锁的过程中都用到了对象头的哪些数据？ 锁的信息存在java对象头里面。如果对象是数组，这虚拟机会用3个Word(32位虚拟机，32bit)来存对象头，如果对象是非数组类型，则用2个Word来存对象头，其中 有一个word用来存储对象的hashcode和锁信息，32bit，叫Mark word。 Mark Word 不是一个固定的数据结构，具体的信息分布需要先判断2bit的锁标志位，不同的锁标志位，剩余的30bit可能表示不同的意思。 32bit的信息是不够存Monitor线程同步（调度）所需要的信息的，所以重量级锁是有另外的native heap存储的，之后再把指针存在Mark word 中。 锁状态 25 bit 4bit 1bit 2bit 23bit 2bit 是否是偏向锁 锁标志位 轻量级锁 指向栈中锁记录的指针 00 重量级锁 指向互斥量（重量级锁）的指针 10 GC标记 空 11 偏向锁 线程ID Epoch 对象分代年龄 1 01 锁的优化 在jdk1.6之前synchronized是单纯的重量级锁实现，由于重量级锁，线程获取不到锁就需要挂起等待唤醒，这种切换涉及到了用户态到内核态的转换，开销还是比较大的。在jdk1.6加入了偏向锁、轻量级锁。只有一个线程请求对象锁的时候，启用的是偏向锁，当有第二个线程竞争的时候（应该说是偏向状态出现锁竞争），这个时候会升级为轻量级锁（cas 自旋锁），处于轻量级锁状态下，如果自旋10次（可以配置）还是获取锁失败，则锁升级为重量级锁。 偏向锁 ：在大部分情况下一个同步方法或者一个同步代码块不存在多线程的竞争，这样只需要在对象头和当前线程的栈帧中存一个线程ID，每次获取锁的时候只需要判断一些线程ID释放一致就行了，不用进行CAS的加锁和解锁。如果有第二个线程需要竞争锁，这个时候会通过CAS设置Mark Word中的锁状态位，成功则修改为偏向当前线程，失败的话就进行锁的升级，锁升级涉及到偏向锁的撤销，会将偏向锁线程挂起。 偏向锁会将Mark Word设置为当前threadId，那么hashCode存哪里了? 如果处于偏向的的对象调用的hashCode方法就会触发撤销偏向锁 轻量级锁：线程在获取锁之前，当前线程会在栈帧中创建一个Mark Word的拷贝作为锁记录，官方称为Displaced Mark Word。然后将对象头中替换成锁记录的指针（CAS），如果失败则会自旋10次（在1.6之后是采用自适应锁，这个时间已经不能自己配置了），之后升级为重量级锁。 为什么一定要拷贝到Displaced Mark Word，而不直接就采用一个threadId？一个原因是需要恢复hash和GC分代的信息，一个就是解决重入锁的问题。 重量级锁：ObjectMonitor有更多的空间来实现线程同步，可以更好像的实现线程同步（挂起和唤醒）。轻量级锁为什么要膨胀？ 优缺点 锁 优点 缺点 使用场景 偏向锁 只需比较threadId释放是否是当前线程没有CAS的消耗 当出现锁竞争的时候会有锁撤销的消耗 单个线程 轻量级锁 线程一直在用户态，不用挂起。没有线程切换的消耗 自旋会导致CPU做无用功 同步代码块执行较快。 重量级锁 线程挂起，不用进行自旋 用户态到内核态转化，开销大 同步代码块执行时间较长，锁竞争激烈 J.U.C中的锁 上面锁的synchronzied是JVM的内置锁，在1.6之前性能比较差，Doug Lea就写个并发框架(java.util.current)，在1.6之后synchronized的性能已经跟Lock查不不多了，但是还少了锁的获取和释放的操作性，不支持超时，只有一个condition等。 AQS AbstractQueueSynchronizer是J.U.C中其他锁或者同步器的基础框架（ReentrantLock,ReentrantReadWriteLock,CountdDownLatch,CyclicBarrier等），这些框架在AQS的基础上进行了扩展，通常是继承AQS然后实现了AQS的几个抽象方法。 我在上面说ObjectMonitor有说到，同步器为了完成同步工作，需要3个东西： 用于同步的状态量 一个队列或者一个保存等待线程的容器 线程的挂起和唤醒 我们看下AQS是怎么围绕这3个部分进行实现的。 1. 同步的状态量(互斥量) AQS中维护一个volatile 的int 变量state，线程通过cas来获取这个互斥量。AQS提供一下几个方法来对state变量进行操作。 getState() compareAndSetState(int expect, int update) setState(int state) 有了上面的3个方法，同步器就可以实现自旋锁，但是如果想实现公平锁，上面的三个方法或者说单用一个state变量是无法做到了。这个时候就需要一个FIFO的队列来维护这些线程。此外为了实现重入锁，我们还得需要一个变量来存当前持有的锁是什么线程。 2.等待线程队列 AQS 用了一个CLH的双向队列，Node的数据结构大概如下： 1234567statci final class Node&#123; volatile int waitStatus; volatile Node prev; volatile Node next; Node nextWaiter;&#125; AQS维护一个头节点和一个尾节点，入队的时候通过CAS加入到未尾节点中。入队后开始开始自旋。 1234567891011121314151617181920212223final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); // 前趋节点是头节点，并且获取到互斥量，说明获取锁成功。 if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; // 判断是否需要挂起 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 从上面代码片段可以看出，加入队列的线程节点并不是完全的自旋，shouldParkAfterFailedAcquire方法判断当前线程是否需要挂起。 下面的这个方法表明shouldParkAfterFailedAcquire 会在调用1到2次后会返回true（如果期间节点没有发生改变的话）。也就是自旋锁只自旋了2次就会被挂起。 12345678910111213141516171819202122232425262728private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; int ws = pred.waitStatus; if (ws == Node.SIGNAL) /* * This node has already set status asking a release * to signal it, so it can safely park. */ return true; if (ws &gt; 0) &#123; /* * Predecessor was cancelled. Skip over predecessors and * indicate retry. */ do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; /* * 进行到这里说明前驱节点的waitStatus 是0 或者PROPAGATE ，利用CAS的设置为SIGNAL，这样下次自旋就会阻塞了，这里不返回true的目的是让当前线程再自旋一次，确保挂起前是无法获取到锁（避免发生刚挂起就被唤醒的情况）。 * waitStatus must be 0 or PROPAGATE. Indicate that we * need a signal, but don&apos;t park yet. Caller will need to * retry to make sure it cannot acquire before parking. */ compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false; &#125; 3.线程的挂起和唤醒 AQS中实现线程的挂起和唤醒是通过LockSupport这个工具，LockSupport的底层实现是调用Unsafe的native方法。 1234567891011public static void unpark(Thread thread) &#123; if (thread != null) UNSAFE.unpark(thread);&#125;public static void park(Object blocker) &#123; Thread t = Thread.currentThread(); setBlocker(t, blocker); UNSAFE.park(false, 0L); setBlocker(t, null);&#125; ConditionObject ConditionObject 是AQS实现类似object类的wait/notify/notifyAll方法的，ConditionObject提供的是aw ait/awaitNanos(long nanos)/awaitUtil(Date date)/awaitUniterrutibly()/signal()/signalAll()。底层的实现也是各自维护一个队列，Node.nextWaiter。 对于超时机制也是用LockSupport中的实现，但并不是所有情况下都使用系统的休眠，有个休眠的自旋时间阀值spinForTimeoutThreshold = 1000L ，默认是1000 纳秒，少于这个阀值的都不用休眠，而是直接自旋。 参考文章 synchronized 与 object’s Monitor AbstractQueuedSynchronizer的介绍和原理分析 J.U.C之AQS：阻塞和唤醒线程 关于synchronized的Monitor Object机制的研究 Intrinsic Locks and Synchronization","categories":[{"name":"jdk","slug":"jdk","permalink":"http://liaojiacan.me/categories/jdk/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"http://liaojiacan.me/tags/多线程/"},{"name":"synchronized","slug":"synchronized","permalink":"http://liaojiacan.me/tags/synchronized/"},{"name":"AQS","slug":"AQS","permalink":"http://liaojiacan.me/tags/AQS/"}]},{"title":"Innodb中的锁总结","slug":"Innodb中的锁总结","date":"2019-02-28T11:22:00.000Z","updated":"2019-05-22T05:43:18.856Z","comments":true,"path":"2019/02/28/Innodb中的锁总结/","link":"","permalink":"http://liaojiacan.me/2019/02/28/Innodb中的锁总结/","excerpt":"","text":"锁的种类 表锁 LOCK TABLE table_name READ : 用读锁锁表，阻塞其他事务修改 LOCK TABLE table_name WRITE: 用写锁锁表，阻塞其他事务读和写 行锁 X锁：排他锁，允许对数据进行删除和更新/插入 S锁：共享锁，允许对数据进行读取，可理解为读锁 锁的兼容性：如果两个事务能对一行数据同时加锁，就认为这个锁是兼容的，如果是要等待其他事务释放，则认为这2个锁是不兼容的。 * X S X 不兼容 不兼容 S 不兼容 兼容 意向锁 MySQL innodb 是支持多粒度锁的，比如可以同时存在表锁和行锁，为了更好的实现多粒度锁，innodb引入了意向锁，在innodb中的意向锁是表级的锁，意向锁与意向锁之间是兼容了，假如不存在表锁，不会有事务在加意向锁的时候阻塞。 IS锁：意向共享锁，表明表中存在一行或者多行的S锁，即在给一行数据加S锁之前必在这个表加IS锁。 IX锁：意向排他锁，表明表中存在一行或者多行的X锁，即在给一行数据加S锁之前必在这个表加IX锁。 思考：为什么需要这个意向锁？ 我们比如思考一下这个场景，事务1给某个表中的N行加了行锁，这个时候事务2想给这个表加个表锁，那么事务2需要确认的事情有： 这个表是否存在不兼容的表锁，比如我想加个X锁，但是已经有其他事务加了S锁。 这个表中是否已经存在不兼容的行锁。 显然在确认第二个条件时，如果采用全表扫描的话，效率太低，所以意向锁的目的就是在粗粒度的锁（表锁）可以快速判断是否与低粒度的锁存在冲突。 * IX S IS X 不兼容 不兼容 不兼容 IX 不兼容 兼容 不兼容 S 不兼容 不兼容 兼容 IS 不兼容 兼容 兼容 innodb行锁的形式或者算法 Innodb中行锁都是加在索引上的，针对不同的场景都有不同的加锁策略。 Record Lock 记录锁，顾名思义就是锁住记录本身，锁主主键和唯一索引，如果表中没有加任何索引，锁会加在隐式生成的主键上。 Gap Lock 间隙锁，当存在范围扫描的时候，给扫描范围加间隙锁，[起始地址，终止) 不同事务对同一个区间加间隙锁是不冲突的，所以S Gap Lock 和 X Gap Lock不存在区别。 READ_COMMITED 隔离级别下不会启用间隙锁。 Next Key Lock 临键锁，Record Lock + Gap Lock ,锁主当前值区间+下一个区间(不一定)。 12345610, 11, 13, 20(negative infinity, 10](10, 11](11, 13](13, 20](20, positive infinity) 解决的是当前读下的幻读问题。 Insert Intention Lock 插入意向锁，是一种特殊的间隙锁；insert之前会向插入区间加上Insert Intention Lock。 Gap Lock / Next key Lock 与 Insert Intention Lock不兼容。 Gap lock 和Next key lock 的目的就是防止有数据插入间隙 不同SQL产生的锁 https://dev.mysql.com/doc/refman/5.7/en/innodb-locks-set.html SELECT…FROM 一致性非锁定读，除了在 SERIALIZABLE隔离级别下会存在S锁，其他隔离级别下都不会有锁。 SELECT…FOR UPDATE/SELECT…LOCK IN SHARE MODE 也叫做当前读，会在给扫描过程中的索引加X或S锁，跟Where条件实际上没有强关系，只跟扫描的过程有关，所以where条件是否能够命中索引比较重要。 在检索的过程中会给用到的索引加Next Key Lock。不过如果检索条件是唯一索引能定位到一行数据，则只加Record Lock UPDATE…WHERE… 同样给检索到的记录加next key lock, 如果WHERE条件中是使用主键或者唯一索引进行限定的话，只在索引加了Record Lock。 如果UPDATE的是聚簇索引记录，会对受影响的辅助索引加隐式锁，当有新的辅助索引插入前的重复检测，以及在执行插入新的辅助索引记录时，对受影响的索引记录加S锁。 DELETE FROM … WHERE … 与UPDATE基本一致 INSERT 给插入索引的记录加一个X锁 插入前前会加个Insert Intention Lock。 如果发生唯一键异常（duplicate-key error ），会在原记录上加S锁，这个如果和delete和update一起使用可能会导致死锁。 INSERT … ON DUPLICATE KEY UPDATE 跟INSERT语句有点不同的就是，当发生重复键异常是，这里加的是排他锁，而不是共享锁。 如果是唯一键异常，则加的是Next key lock。 REPLACE 如果没有发生冲突，则行为跟INSERT是一致的。 如果发生冲突，则对唯一键加的是Next key lock。 INSERT INTO T SELECT … FROM S WHERE … 给子查询语句加的X锁。 如果是READ COMMITED 隔离基本，则采用的是快照读 外键约束 在进行外键约束检测时，会给记录加行级共享锁。 死锁 死锁是只当2个或者2个以上的事务抢占各自的资源，导致的相互等待的现象。 案例 Insert-ignore-和update-导致的死锁问题分析 解决死锁和进行死锁检测 设置超时时间,事务有限时间超时,回滚其中一个事务。 1234567mysql&gt; show variables like &quot;%innodb_lock_wait_timeout%&quot;;+--------------------------+-------+| Variable_name | Value |+--------------------------+-------+| innodb_lock_wait_timeout | 50 |+--------------------------+-------+1 row in set (0.07 sec) wait-graph 等待图死锁检测 锁的信息链 事务等待链","categories":[{"name":"数据库","slug":"数据库","permalink":"http://liaojiacan.me/categories/数据库/"}],"tags":[{"name":"Innodb","slug":"Innodb","permalink":"http://liaojiacan.me/tags/Innodb/"}]},{"title":"Insert ignore 和update 导致的死锁问题分析","slug":"Insert-ignore-和update-导致的死锁问题分析","date":"2019-02-27T12:13:00.000Z","updated":"2019-05-22T05:43:18.857Z","comments":true,"path":"2019/02/27/Insert-ignore-和update-导致的死锁问题分析/","link":"","permalink":"http://liaojiacan.me/2019/02/27/Insert-ignore-和update-导致的死锁问题分析/","excerpt":"","text":"业务逻辑以及死锁现象 业务逻辑大概如下： 在粉丝表新增一条关系记录。 假如关注者也是当前用户的粉丝，则更新2者的标记为相互关注。 业务代码如下, 最初是考虑用insert ignore 来解决幂等的问题，所以允许重复调用。 123456789101112131415161718192021//是否 关注的用户是操作者的粉丝（互粉）boolean isHisFans = fansDao.isFans(fansUserId,followingUserId);// insert ignore into // fans(fans_user_id,following_user_id,following_each_other)// values(#&#123;fansUserId&#125;, #&#123;followingUserId&#125;,#&#123;followingEachOther&#125;)int updateNum = fansDao.addFans(fansUserId, followingUserId,isHisFans);boolean addAndCheck = false;if(isHisFans)&#123; // update fans // set following_each_other = #&#123;followingEachOther&#125; // where (fans_user_id = #&#123;fansUserId&#125; and following_user_id = #&#123;followingUserId&#125; ) or (fans_user_id = #&#123;followingUserId&#125; and following_user_id = #&#123;fansUserId&#125; ) int num = fansDao.setFollowingEachOther(followingUserId,fansUserId,true); if( num &gt;0 )&#123; //重新调整数据 addAndCheck = true; &#125;&#125; 线上产生的死锁的信息(show engine innodb status) 1234567891011121314151617181920212223242526272829303132333435363738394041LATEST DETECTED DEADLOCK------------------------2019-02-12 23:24:45 7fa406a4f700*** (1) TRANSACTION:TRANSACTION 515545684, ACTIVE 0 sec starting index readmysql tables in use 1, locked 1LOCK WAIT 3 lock struct(s), heap size 1184, 2 row lock(s)MySQL thread id 2121, OS thread handle 0x7fa406b12700, query id 1702086 10.10.17.63 jb-glive Searching rows for updateupdate fans set following_each_other = 1 where (fans_user_id = &apos;1776093&apos; and following_user_id = &apos;1331089&apos; ) or (fans_user_id = &apos;1331089&apos; and following_user_id = &apos;1776093&apos; )*** (1) WAITING FOR THIS LOCK TO BE GRANTED:RECORD LOCKS space id 1023 page no 37913 n bits 400 index `UK_USER_ID` of table `glive`.`fans` trx id 515545684 lock_mode X locks rec but not gap waitingRecord lock, heap no 334 PHYSICAL RECORD: n_fields 3; compact format; info bits 0 0: len 7; hex 31333331303839; asc 1331089;; 1: len 7; hex 31373736303933; asc 1776093;; 2: len 8; hex 8000000001282c31; asc (,1;;*** (2) TRANSACTION:TRANSACTION 515545683, ACTIVE 0 sec starting index readmysql tables in use 1, locked 15 lock struct(s), heap size 1184, 4 row lock(s)MySQL thread id 3485, OS thread handle 0x7fa406a4f700, query id 1702085 10.10.17.61 jb-glive Searching rows for updateupdate fans set following_each_other = 1 where (fans_user_id = &apos;1776093&apos; and following_user_id = &apos;1331089&apos; ) or (fans_user_id = &apos;1331089&apos; and following_user_id = &apos;1776093&apos; )*** (2) HOLDS THE LOCK(S):RECORD LOCKS space id 1023 page no 37913 n bits 400 index `UK_USER_ID` of table `glive`.`fans` trx id 515545683 lock_mode X locks rec but not gapRecord lock, heap no 334 PHYSICAL RECORD: n_fields 3; compact format; info bits 0 0: len 7; hex 31333331303839; asc 1331089;; 1: len 7; hex 31373736303933; asc 1776093;; 2: len 8; hex 8000000001282c31; asc (,1;;*** (2) WAITING FOR THIS LOCK TO BE GRANTED:RECORD LOCKS space id 1023 page no 38446 n bits 360 index `UK_USER_ID` of table `glive`.`fans` trx id 515545683 lock_mode X locks rec but not gap waitingRecord lock, heap no 294 PHYSICAL RECORD: n_fields 3; compact format; info bits 0 0: len 7; hex 31373736303933; asc 1776093;; 1: len 7; hex 31333331303839; asc 1331089;; 2: len 8; hex 8000000001282c59; asc (,Y;;*** WE ROLL BACK TRANSACTION (1) 锁分析： 事务T2持有 (fans_user_id=1331089,following_user_id=1776093,主键=hex8000000001282c31) X 锁； 事务T2等待行锁 (fans_user_id=1776093,following_user_id=1331089,主键=hex8000000001282c59) X 锁； 事务T1等待T2持有的锁。 事务T1此时应该还持有T2等待的锁，只是没显示出来。 看起来就是典型的AB-BA问题 重现 我们先简化上面的业务代码逻辑，假设fans_user_id=11000,following_user_id=10086，其实就是执行2个SQL： 12341. insert ignore into fans(fans_user_id,following_user_id) values(11000,10086);2. update fans set following_each_other = 1 where (fans_user_id = &apos;11000&apos; and following_user_id = &apos;10086&apos; ) or (fans_user_id = &apos;10086&apos; and following_user_id = &apos;11000&apos; ); 场景一：不存在fans_user_id=11000,following_user_id=10086的这条数据。 T1 T2 &gt;begin; &gt;begin; insert ignore into fans(fans_user_id,following_user_id) values(11000,10086); * * insert ignore into fans(fans_user_id,following_user_id) values(11000,10086); //阻塞 update fans set following_each_other = 1 where (fans_user_id = ‘11000’ and following_user_id = ‘10086’ ) or (fans_user_id = ‘10086’ and following_user_id = ‘11000’ ) * commit; insert 语句开始执行 * update fans set following_each_other = 1 where (fans_user_id = ‘11000’ and following_user_id = ‘10086’ ) or (fans_user_id = ‘10086’ and following_user_id = ‘11000’ ) * commit; 分析： 由于数据库并没有这条记录，所以事务T1在执行insert ignore into 时可以执行成功，并给这行数据加了X锁。 事务T2在执行insert ignore into 时由于获取不到行锁，直接阻塞。 后面都是顺序执行，所以并不会出现死锁的问题。 场景二：数据库已经存在fans_user_id=11000,following_user_id=10086的这条数据。 T1 T2 &gt;begin; &gt;begin; insert ignore into fans(fans_user_id,following_user_id) values(11000,10086); * * insert ignore into fans(fans_user_id,following_user_id) values(11000,10086); //执行成功 update fans set following_each_other = 1 where (fans_user_id = ‘11000’ and following_user_id = ‘10086’ ) or (fans_user_id = ‘10086’ and following_user_id = ‘11000’ ) * 阻塞等待 * * update fans set following_each_other = 1 where (fans_user_id = ‘11000’ and following_user_id = ‘10086’ ) or (fans_user_id = ‘10086’ and following_user_id = ‘11000’ ) * Deadlock found when trying to get lock; try restarting transaction 分析： 由于数据库已经存在该记录，所以事务T1执行insert ignore into 会插入失败，并给该记录加了个S锁。 由于S锁是相互兼容的，所以事务T2也给该记录加了S锁。 T1继续执行update语句，尝试给2行数据加X锁，但是其中有一行数据已经被T2加了S锁，此时T1回到等待队列中继续等待。 T2继续执行update语句，尝试给2行数据加X锁，但是发现T1已经对这2行数据请求了X锁，且在等待T2释放S锁，而T1又因为T2不释放S锁而无法升级为X锁。 可以参考mysql官方的例子，原理是一样的。innodb-死锁例子 下面是场景二的DEADLOCK信息（show engine innodb status），你会发现其实跟生产环境的锁是又区别的，线上的死锁信息中T2 持有的是一个X锁（这个不知道怎么解释，无法重现） 1234567891011121314151617181920212223242526272829303132333435363738394041LATEST DETECTED DEADLOCK------------------------2019-02-27 14:15:00 0x7000034b5000*** (1) TRANSACTION:TRANSACTION 620686, ACTIVE 19 sec starting index readmysql tables in use 1, locked 1LOCK WAIT 5 lock struct(s), heap size 1136, 4 row lock(s)MySQL thread id 63, OS thread handle 123145355350016, query id 1172740 localhost 127.0.0.1 root updatingupdate fans set following_each_other = 1 where (fans_user_id = &apos;11000&apos; and following_user_id = &apos;10086&apos; ) or (fans_user_id = &apos;10086&apos; and following_user_id = &apos;11000&apos; )*** (1) WAITING FOR THIS LOCK TO BE GRANTED:RECORD LOCKS space id 107 page no 7 n bits 624 index UK_USER_ID of table `test`.`fans` trx id 620686 lock_mode X locks rec but not gap waitingRecord lock, heap no 280 PHYSICAL RECORD: n_fields 3; compact format; info bits 0 0: len 5; hex 3131303030; asc 11000;; 1: len 5; hex 3130303836; asc 10086;; 2: len 8; hex 800000000143abeb; asc C ;;*** (2) TRANSACTION:TRANSACTION 620687, ACTIVE 16 sec starting index readmysql tables in use 1, locked 13 lock struct(s), heap size 1136, 2 row lock(s)MySQL thread id 61, OS thread handle 123145357578240, query id 1172741 localhost 127.0.0.1 root updatingupdate fans set following_each_other = 1 where (fans_user_id = &apos;11000&apos; and following_user_id = &apos;10086&apos; ) or (fans_user_id = &apos;10086&apos; and following_user_id = &apos;11000&apos; )*** (2) HOLDS THE LOCK(S):RECORD LOCKS space id 107 page no 7 n bits 624 index UK_USER_ID of table `test`.`fans` trx id 620687 lock mode SRecord lock, heap no 280 PHYSICAL RECORD: n_fields 3; compact format; info bits 0 0: len 5; hex 3131303030; asc 11000;; 1: len 5; hex 3130303836; asc 10086;; 2: len 8; hex 800000000143abeb; asc C ;;*** (2) WAITING FOR THIS LOCK TO BE GRANTED:RECORD LOCKS space id 107 page no 7 n bits 624 index UK_USER_ID of table `test`.`fans` trx id 620687 lock_mode X locks rec but not gap waitingRecord lock, heap no 279 PHYSICAL RECORD: n_fields 3; compact format; info bits 0 0: len 5; hex 3130303836; asc 10086;; 1: len 5; hex 3131303030; asc 11000;; 2: len 8; hex 800000000143abdb; asc C ;;*** WE ROLL BACK TRANSACTION (2) 解决方法 在这个案例中，发生死锁的原因主要是insert ignore 在数据已经存在时只是加了S锁。所以解决的办法其实又几个。 使用其他的幂等处理办法，不要依赖insert ignore。在这个案例中，其实应该直接使用insert，不允许重复执行，可以捕获唯一key异常来获取updateNum进行下个业务处理。 直接在业务开头使用select for … update 来加排他锁保证业务是串形执行（只是从死锁这个问题考虑，如果考虑性能需要找其他方案）。 假如就非得使用insert ignore 和 update，那么我们可以考虑在这个业务加个重试，数据库的死锁并不是致命的，设置好数据库的事物超时时间，然后遇到死锁问题，我们可以在业务进行重试解决。 未分析清楚的点 为什么线上的锁他是一个X锁，并不是一个S锁？是否有场景三？MySQL官方文档有一段话，感觉有点关联，但是无法对应上现象,说的是insert 和 delete 语句其实并不是真正原子的行锁。 InnoDB uses automatic row-level locking. You can get deadlocks even in the case of transactions that just insert or delete a single row. That is because these operations are not really “atomic”; they automatically set locks on the (possibly several) index records of the row inserted or deleted.","categories":[{"name":"死锁","slug":"死锁","permalink":"http://liaojiacan.me/categories/死锁/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://liaojiacan.me/tags/MySQL/"},{"name":"innodb","slug":"innodb","permalink":"http://liaojiacan.me/tags/innodb/"}]},{"title":"JDK1.7 ConcurrentHashMap的源码解读","slug":"JDK1-7-ConcurrentHashMap的源码解读","date":"2019-02-26T03:18:00.000Z","updated":"2019-05-22T05:43:18.857Z","comments":true,"path":"2019/02/26/JDK1-7-ConcurrentHashMap的源码解读/","link":"","permalink":"http://liaojiacan.me/2019/02/26/JDK1-7-ConcurrentHashMap的源码解读/","excerpt":"","text":"一、 ConcurrentHashMap的数据结构(JDK7)。 segments[] : Segment&lt;K,V&gt; extends ReentrantLock 分段锁，HashMap 用一个Entry[] table 去存数据，ConcurrentHashMap 则是将 这个table 拆分出 n 个段（一个最接近concurrencyLevel的2的幂）分别存储，Segment 中的 用一个HashEntry table[] 来存数据，table中hash冲突的解决算法基本与HashMap一致。同一个段的put和get操作是需要加锁的，Segment继承了ReentrantLock 故有了锁的功能。 concurrencyLevel : int 并发等级，默认是16，可以在构造函数指定该值，这个值直接影响segment数组的大小。如果这个值不是2的幂，则会计算出一个最接近（向上取）的2的幂来初始化segments数组。 segmentMask : int 掩码，是一个bit位都是1的数，跟segments的长度有关，比如默认segments的长度是16=2的4次方（二进制为10000）。假如我们需要获取到一个数落在[0,16) 这个区间，则只需要用这个数跟1111做与运算, 得到的结果肯定是落在0到16之间，这个比取模运算更加高效。 segmentShift : int 位移数，获取高ssize(segments size)位需要的左移的位数（32-ssize），hash函数算出来的是一个32 位int的整型，ConcurrentHashMap 对segments的hash算法采用的是一个取高位进行hash的做法。比如一个key算出来的值为1024，如果我想取高ssize位 ，假如ssize为4，那么就要将1024&gt;&gt;&gt;(32-4)，取得高4位。获取到高4位后会与segmentMask进行与运算获取到一个[0,ssize)的数。这就是ConcurrentHashMap中对segment采用的hash算法。 为什么要采用高位运算？ 源码中似乎没有说明，我猜是为了跟segment中的HashEntry[] table 的hash算法区分开来，降低冲突的概率。假如采用同样的hash算法，有2个key Hash到同一个segment中那么再进行 段中的二次hash的时候可能还是命中到同一个节点导致链越来越长。 1234// segment[] 的hash算法 （hash的高位参与运算） int j = (hash &gt;&gt;&gt; segmentShift) &amp; segmentMask;// table[] 的hash算法 （hash的低位参与运算） int index = (tab.length - 1) &amp; hash; 二、segment中独占锁的加锁逻辑 分段锁的目的就是将锁冲突分离开，只有hash到同一个segment中的操作才会存在锁竞争，CurrentHashMap 中put和remove以及size是有加锁操作的。 put操作加锁 1HashEntry&lt;K,V&gt; node = tryLock() ? null :scanAndLockForPut(key, hash, value); reomve操作加锁 12if (!tryLock()) scanAndLock(key, hash); 如果 tryLock() 不能能加锁成功则进行自旋，scanAndLockForPut和scanAndLock有点区别但是逻辑差不多。 1.有限重试次数，多核心CPU的话是64次，单核1次，超过次数则阻塞等待获取锁。 2.获取锁之前和获取到锁期间头节点不能发生改变，否则需要从头开始重试。 12345678910111213141516171819202122232425private void scanAndLock(Object key, int hash) &#123; // similar to but simpler than scanAndLockForPut HashEntry&lt;K,V&gt; first = entryForHash(this, hash); HashEntry&lt;K,V&gt; e = first; int retries = -1; while (!tryLock()) &#123; HashEntry&lt;K,V&gt; f; if (retries &lt; 0) &#123; if (e == null || key.equals(e.key)) retries = 0; else e = e.next; &#125; else if (++retries &gt; MAX_SCAN_RETRIES) &#123; lock(); break; &#125; // 如果头节点发生改变，从头开始扫描 else if ((retries &amp; 1) == 0 &amp;&amp; (f = entryForHash(this, hash)) != first) &#123; e = first = f; retries = -1; &#125; &#125;&#125; get没有加排他锁，是否有线程安全问题？ 先说下结论，ConcurrentHashMap get方法不存在线程安全问题，他的线程安全是由CAS 和 &quot;volatile&quot;保证的: 1. UNSAFE.putOrderedObject/UNSAFE.getObjectVolatile 2. volatile HashEntry&lt;K,V&gt; next; 3. volatile V value; 我们整理下，要保证get不发生线程安全问题需要保证什么？ 1. get操作和put或remove操作并行的时候，get能操作能够获取到正确的segment和头节点table[i]。 2. 在entries的遍历中能顺利走到未节点。 3. 在1和2的前提下get操作时能够保证value值的可见性。 我们先看第1点时怎么保证的，我们都知道java中有个volatile用了保证变量在多线程下的可见性，volatile可以保证可见性，但是不能保证线程安全，如果当前赋值语句依赖当前值时是线程不安全的，比如a +=1 这种操作就是不安全的，显然在ConcurrentHashMap的并不需要这种操作，只存在简单的引用赋值操作。 但是需要注意的是一点，volatile修饰引用型变量时，只能保证当前引用的可见性，对于引用对象的内部变量仍然是无法保证可见性的，这就是为什么在对segments[] 数组和table[] 数组的的操作需要借助Unsafe类，而不是直接segments[i] = new Segment(…); 由前面的分析看，volatile/Unsafe.getObjectVolatile/Unsafe.putOrderedOject保证链当get操作晚与put操作时是可以获取到刚插入的节点(作为一个新头节点连接到旧节点并更新table)，对与一个早于put操作的get操作一个情况就是新插入的元素表头，但是get操作已经获取到了旧表头，所以并不影响get操作进行链表的遍历查找。 我们在看进行remove时是否会影响entries的遍历，从源码中看，HashEntry中的next成员是被volatile修饰的，这就保证了get可以安全得遍历到未节点。 三、size的实现逻辑 假如ConcurrentHashMap采用HashMap维护一个全局的size来变量统计大小，那么为了线程安全，也必定得改用原子类AtomicLong或者全局加锁。这显然与分段锁的设计背离。那么有没有一种比较折衷的办法呢？ ConcurrentHashMap中将size的统计拆分到各个segment取去护，每次执行size的时候将每个segment的count加起来，最终得到的结果就是map的大小。这个看似乎很合理，但是如果在进行统计的过程中有一个segment发生put或者remove操作呢，这样得到的结果就是错误的，显然我们可以在统计前先将每个segment给锁起来，再sum，得到的结果肯定是正确的。 存在一种情况就是你的程序中并发很少，出现并发更新的情况很少，这个时候你执行size的时候将所有的segment加锁和不加锁的情况可能得到的结果是一样的，因为这个时候没有其他线程进行修改。似乎我们可以乐观地考虑一下大部分情况下是不需要进行锁操作的。 Doug Lea采用类一种跟JDK集合类中大多数存在的fail-safe错误检查机制，对在每个segment中于更新操作维护一个modCount来记录更新的次数，统计前和统计后的modCount是一样的说明没有发生变化，当前的统计结果有效。ConcurrentHashMap的size方法的实现逻辑如下： 先采用无锁的方式统计2次，如果前后的modCount总和是一样的，此次统计结果有效，返回结果。 假如前后的modCount总和不一样，第三次进行有锁的统计。 1234567891011121314151617181920212223242526272829303132333435363738394041public int size() &#123; // Try a few times to get accurate count. On failure due to // continuous async changes in table, resort to locking. final Segment&lt;K,V&gt;[] segments = this.segments; int size; boolean overflow; // true if size overflows 32 bits long sum; // sum of modCounts long last = 0L; // previous sum int retries = -1; // first iteration isn&apos;t retry try &#123; for (;;) &#123; //第三次进行上锁 if (retries++ == RETRIES_BEFORE_LOCK) &#123; for (int j = 0; j &lt; segments.length; ++j) ensureSegment(j).lock(); // force creation &#125; sum = 0L; size = 0; overflow = false; for (int j = 0; j &lt; segments.length; ++j) &#123; Segment&lt;K,V&gt; seg = segmentAt(segments, j); if (seg != null) &#123; sum += seg.modCount; int c = seg.count; if (c &lt; 0 || (size += c) &lt; 0) overflow = true; &#125; &#125; // 前后2次的统计结果一致，可以返回 if (sum == last) break; last = sum; &#125; &#125; finally &#123; if (retries &gt; RETRIES_BEFORE_LOCK) &#123; for (int j = 0; j &lt; segments.length; ++j) segmentAt(segments, j).unlock(); &#125; &#125; return overflow ? Integer.MAX_VALUE : size; &#125; 四、Unsafe.getObjectVolatile/Unsafe.putOrderedOject对偏移量的计算问题 ConcurrentHashMap中使用量Unsafe类来对segment数组和table数组进行数组填充和取值操作，其中对位置i的内存偏移计算用了位运算来代替乘法运算 123456// segment[0] 的偏移地址int baseOffset = UNSAFE.arrayBaseOffset(Segment[].class);// 每个位置的大小int indexScale = UNSAFE.arrayIndexScale(Segment[].class);//那么第i个元素的内存偏移就是long offset = baseOffset+i*indexScale ; 上面的计算方法是利用乘法来计算的，但是乘法的计算还是比较慢的，如果能用位运算更佳。由于jvm给对象分配内存的时候会进行内存对对齐，也就是说indexScale其实会是一个2的n次方的数。一个整数i乘以一个2的n次方可以转化成 i&lt;&lt;n; 123456783 * 2 = 3 &lt;&lt; 13 * 4 = 3 &lt;&lt; 23 * 8 = 3 &lt;&lt; 33 * 16 = 3 &lt;&lt; 43 * 32 = 3 &lt;&lt; 53 * 64 = 3 &lt;&lt; 63 * 128 = 3 &lt;&lt; 73 * 256 = 3 &lt;&lt; 8 所以你会看到ConcurrentHashMap中有这样的代码 12345// 31 - Integer.numberOfLeadingZeros(ssize) 这个是求一个数x的2对数 SSHIFT = 31 - Integer.numberOfLeadingZeros(ssize); ... // 所以元素i在内存中的偏移就是 long offset = SBASE +(i&lt;&lt;SSHIFT) 测试用例-ConcurrentHashMap中利用Unsafe进行数组操作的测试用例;","categories":[{"name":"源码解读","slug":"源码解读","permalink":"http://liaojiacan.me/categories/源码解读/"},{"name":"JDK","slug":"源码解读/JDK","permalink":"http://liaojiacan.me/categories/源码解读/JDK/"}],"tags":[{"name":"J.U.C","slug":"J-U-C","permalink":"http://liaojiacan.me/tags/J-U-C/"},{"name":"ConcurrentHashMap","slug":"ConcurrentHashMap","permalink":"http://liaojiacan.me/tags/ConcurrentHashMap/"}]},{"title":"谈谈多语言设计（三）Spring-i18n 拓展之自定义MessageSource","slug":"谈谈多语言设计（三）Spring-i18n-拓展之自定义MessageSource","date":"2018-04-13T08:08:00.000Z","updated":"2019-05-22T05:43:18.862Z","comments":true,"path":"2018/04/13/谈谈多语言设计（三）Spring-i18n-拓展之自定义MessageSource/","link":"","permalink":"http://liaojiacan.me/2018/04/13/谈谈多语言设计（三）Spring-i18n-拓展之自定义MessageSource/","excerpt":"","text":"Spring框架中有两个MessageSource的实现，分别是ResourceBundleMessageSource和ReloadableResourceBundleMessageSource，前者第一次初始化就固定下来，后者可以根据配置文件是否发生变进行更新。 对于Web网页（UI上的文案），这种配置在配置文件的方式是可以接受的，因为一般这些文案都是固定的。但是对于一些需要动态新增配置的场景显然就是不适合了，比如商品信息，抽奖的奖品，直播间的道具，礼物等，这些都是根据运营人员需要动态调整的，显然需要把配置存储在数据库中。 在写这部分的实现的时候，参考了一个开源项目，https://github.com/synyx/messagesource。 感兴趣的同学，可以在我的Github查看完整的代码。https://github.com/liaojiacan/spring-i18n-support UML 关于MessageSourceProvider 在MessageSource的实现中 ，抽出一个Provider层将存储介质解耦，可以在最后的应用中，选择使用JDBC还是Redis还是远程的配置服务中心的实现。 1234567891011public interface MessageSourceProvider &#123; List&lt;MessageEntry&gt; load(); int addMessage(Locale locale,String code,String type,String message); int updateMessage(Locale locale,String code,String type,String message); int deleteMessage(Locale locale,String code);&#125; JdbcMessageSoucreProvider 因为只是简单的对数据进行CURD，所以采用JdbcTemple的方式减少相关的依赖，采用java原生的jdbc也是可以的。 123456789101112131415-- ------------------------------ Table structure for i18n_message-- ----------------------------DROP TABLE IF EXISTS `i18n_message`;CREATE TABLE `i18n_message` ( `code` varchar(250) NOT NULL COMMENT &apos;mapping code&apos;, `locale` varchar(100) NOT NULL COMMENT &apos;language tag&apos;, `type` varchar(100) DEFAULT NULL COMMENT &apos;type for group&apos;, `message` text NOT NULL COMMENT &apos;message content&apos;, `create_time` datetime DEFAULT CURRENT_TIMESTAMP COMMENT &apos;create time&apos;, `update_time` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT &apos;last modify time&apos;, PRIMARY KEY (`code`,`locale`)) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT=&apos;i18n message data&apos;;SET FOREIGN_KEY_CHECKS = 1; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145public class JdbcMessageSoucreProvider implements MessageSourceProvider &#123; private JdbcTemplate jdbcTemplate; protected static final String QUERY_TPL_INSERT_MESSAGE_ENTRY = &quot;INSERT INTO %s (%s, %s, %s, %s) VALUES (?, ?, ?, ?)&quot;; protected static final String QUERY_TPL_DELETE_MESSAGE_ENTRY = &quot;DELETE FROM %s WHERE %s = ? and %s= ?&quot;; protected static final String QUERY_TPL_SELECT_MESSAGE_ENTRIES = &quot;SELECT %s,%s,%s,%s FROM %s&quot;; protected static final String QUERY_TPL_UPDATE_MESSAGE_ENTRY = &quot;UPDATE %s set %s=?,%s=?,%s=? WHERE %s=? and %s=?&quot;; private String localeColumn = &quot;locale&quot;; private String typeColumn = &quot;type&quot;; private String codeColumn = &quot;code&quot;; private String messageColumn = &quot;message&quot;; private String tableName = &quot;i18n_message&quot;; private String delimiter = &quot;`&quot;; @Override public List&lt;MessageEntry&gt; load() &#123; // @formatter:off String sql = String.format(getQueryTplSelectMessageEntries(), addDelimiter(getCodeColumn()), addDelimiter(getLocaleColumn()), addDelimiter(getTypeColumn()), addDelimiter(getMessageColumn()), addDelimiter(getTableName())); return jdbcTemplate.query(sql,new BeanPropertyRowMapper(MessageEntry.class)); // @formatter:on &#125; @Override public int addMessage(Locale locale, String code, String type, String message) &#123; // @formatter:off String sql = String.format(getQueryTplInsertMessageEntry(), addDelimiter(getTableName()), addDelimiter(getLocaleColumn()), addDelimiter(getCodeColumn()), addDelimiter(getTypeColumn()), addDelimiter(getMessageColumn())); // @formatter:on return jdbcTemplate.update(sql,locale.toLanguageTag(),code,type,message); &#125; @Override public int updateMessage(Locale locale, String code, String type, String message) &#123; // @formatter:off String sql = String.format(getQueryTplUpdateMessageEntry(), addDelimiter(getTableName()), addDelimiter(getLocaleColumn()), addDelimiter(getTypeColumn()), addDelimiter(getMessageColumn()), addDelimiter(getCodeColumn()),addDelimiter(getLocaleColumn())); // @formatter:on return jdbcTemplate.update(sql,locale.toLanguageTag(),type,message,code,locale.toLanguageTag()); &#125; @Override public int deleteMessage(Locale locale, String code) &#123; String sql = String.format(getQueryTplDeleteMessageEntry(),addDelimiter(getTableName()),addDelimiter(getCodeColumn()),addDelimiter(getLocaleColumn())); return jdbcTemplate.update(sql,code,locale.toLanguageTag()); &#125; /** * Method that &quot;wraps&quot; a field-name (or table-name) into the delimiter. * @param name the name of the field/table * @return the wrapped field/table */ protected String addDelimiter(String name) &#123; return String.format(&quot;%s%s%s&quot;, delimiter, name, delimiter); &#125; public JdbcTemplate getJdbcTemplate() &#123; return jdbcTemplate; &#125; public void setJdbcTemplate(JdbcTemplate jdbcTemplate) &#123; this.jdbcTemplate = jdbcTemplate; &#125; public static String getQueryTplInsertMessageEntry() &#123; return QUERY_TPL_INSERT_MESSAGE_ENTRY; &#125; public static String getQueryTplDeleteMessageEntry() &#123; return QUERY_TPL_DELETE_MESSAGE_ENTRY; &#125; public static String getQueryTplSelectMessageEntries() &#123; return QUERY_TPL_SELECT_MESSAGE_ENTRIES; &#125; public static String getQueryTplUpdateMessageEntry() &#123; return QUERY_TPL_UPDATE_MESSAGE_ENTRY; &#125; public String getLocaleColumn() &#123; return localeColumn; &#125; public void setLocaleColumn(String localeColumn) &#123; this.localeColumn = localeColumn; &#125; public String getTypeColumn() &#123; return typeColumn; &#125; public void setTypeColumn(String typeColumn) &#123; this.typeColumn = typeColumn; &#125; public String getCodeColumn() &#123; return codeColumn; &#125; public void setCodeColumn(String codeColumn) &#123; this.codeColumn = codeColumn; &#125; public String getMessageColumn() &#123; return messageColumn; &#125; public void setMessageColumn(String messageColumn) &#123; this.messageColumn = messageColumn; &#125; public String getTableName() &#123; return tableName; &#125; public void setTableName(String tableName) &#123; this.tableName = tableName; &#125; public String getDelimiter() &#123; return delimiter; &#125; public void setDelimiter(String delimiter) &#123; this.delimiter = delimiter; &#125; RefreshableMessageSource RefreshableMessageSource的实现相对简单，在初始化的时候将MessageSourceProvider的数据解析成MessageFormat存在Map中，解析的时候根据code和locale索引到对应的MessageFormat。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677/** * @author liaojiacan https://github.com/liaojiacan */public class RefreshableMessageSource extends AbstractMessageSource implements Refreshable,InitializingBean&#123; private MessageSourceProvider provider; /** * Setting : return origin code when the message not found. */ protected Boolean returnUnresolvedCode = false; /** * The MessageFormat cache */ private Map&lt;String,Map&lt;Locale,MessageFormat&gt;&gt; messageEntryMap = Collections.emptyMap(); public RefreshableMessageSource(MessageSourceProvider provider) &#123; this.provider = provider; &#125; @Override public void refresh()&#123; List&lt;MessageEntry&gt; messageEntries = provider.load(); if(!CollectionUtils.isEmpty(messageEntries))&#123; final Map&lt;String,Map&lt;Locale,MessageFormat&gt;&gt; finalMap = new HashMap&lt;&gt;(); messageEntries.forEach(messageEntry -&gt; &#123; String code = messageEntry.getCode(); Locale locale = Locale.forLanguageTag(messageEntry.getLocale()); Map&lt;Locale, MessageFormat&gt; localeMapping = finalMap.get(code); if(localeMapping == null)&#123; localeMapping = new HashMap&lt;&gt;(); finalMap.put(code,localeMapping); &#125; localeMapping.put(locale,createMessageFormat(messageEntry.getMessage(),locale)); &#125;); messageEntryMap = finalMap; &#125; &#125; @Override protected MessageFormat resolveCode(String code, Locale locale) &#123; Map&lt;Locale, MessageFormat&gt; localeMessageMap = messageEntryMap.get(code); if(localeMessageMap != null )&#123; MessageFormat mf = localeMessageMap.get(locale); if(mf!=null)&#123; return mf; &#125; &#125; if(returnUnresolvedCode)&#123; return createMessageFormat(code,locale); &#125; return null; &#125; @Override public void afterPropertiesSet() throws Exception &#123; this.refresh(); &#125; public MessageSourceProvider getProvider() &#123; return provider; &#125; public void setProvider(MessageSourceProvider provider) &#123; this.provider = provider; &#125; public Boolean getReturnUnresolvedCode() &#123; return returnUnresolvedCode; &#125; public void setReturnUnresolvedCode(Boolean returnUnresolvedCode) &#123; this.returnUnresolvedCode = returnUnresolvedCode; &#125;&#125;","categories":[{"name":"架构总结","slug":"架构总结","permalink":"http://liaojiacan.me/categories/架构总结/"}],"tags":[{"name":"多语言","slug":"多语言","permalink":"http://liaojiacan.me/tags/多语言/"},{"name":"i18n","slug":"i18n","permalink":"http://liaojiacan.me/tags/i18n/"}]},{"title":"Idea使用骨架生成项目卡住的解决办法","slug":"Idea使用骨架生成项目卡住的解决办法","date":"2018-03-09T11:01:00.000Z","updated":"2019-05-22T05:43:18.855Z","comments":true,"path":"2018/03/09/Idea使用骨架生成项目卡住的解决办法/","link":"","permalink":"http://liaojiacan.me/2018/03/09/Idea使用骨架生成项目卡住的解决办法/","excerpt":"","text":"Idea在使用骨架生成项目时（Create from archetype）有时候会发现卡住了，控制台停留在 1[INFO] Generating project in Batch mode 通过debug日志发现是搜索archetype-catalog.xml卡住了 12[INFO] Generating project in Batch mode[DEBUG] Searching for remote catalog: http://repo.maven.apache.org/maven2/archetype-catalog.xml 解决方法： 修改archetypeCatalog参数，archetypeCatalog=internal。Idea可以在maven的runner配置中指定。如图： archetypeCatalog参数取值可以从maven的文档查到.Generate project using an alternative catalog archetypeCatalog 可配置的值有 internal to use the internal catalog only. local to use the local catalog only. remote to use the maven’s remote catalog. 12No catalog is currently provided.The default value is remote,local. Thus the local catalog is shown just after the remote one. 默认是remote,local. 这里解决方法其实有两个， 一个就是上面所说修改archetypeCatalog=internal,直接使用网络。另外一个就是修改远程仓库，如使用阿里的镜像。","categories":[{"name":"工具使用","slug":"工具使用","permalink":"http://liaojiacan.me/categories/工具使用/"}],"tags":[{"name":"Idea","slug":"Idea","permalink":"http://liaojiacan.me/tags/Idea/"},{"name":"archetypeCatalog","slug":"archetypeCatalog","permalink":"http://liaojiacan.me/tags/archetypeCatalog/"}]},{"title":"谈谈多语言设计（二）之Spring多语言","slug":"谈谈多语言设计（二）之Spring多语言","date":"2018-03-08T11:07:00.000Z","updated":"2019-05-22T05:43:18.862Z","comments":true,"path":"2018/03/08/谈谈多语言设计（二）之Spring多语言/","link":"","permalink":"http://liaojiacan.me/2018/03/08/谈谈多语言设计（二）之Spring多语言/","excerpt":"","text":"现在大部分成熟的web框架默认就支持多语言，如果业务比较简单，使用框架自身的多语言支持就可以了。本文将以SpringMvc为例介绍一下JavaWeb的多语言中的一些关键类。 关键字 i18n Locale LocaleContext MessageSource I18N i18n(其来源是英文单词 internationalization的首末字符i和n，18为中间的字符数),除了i18n还有L10n、g11n、m17n。 Locale Locale是区域信息，通常locale信息包含应该语言信息和区域标识符，如zh_CN:zh为中文,CN为中国的国家代码。常见的Locale代码可以上网获取。 Locale Codes。java中的Locale.java 也定义了常见的区域信息。我们应该尽量使用Locale类型来表达地域信息变量，不应该使用String类型 12345678910111213141516171819202122232425static public final Locale ENGLISH = createConstant(&quot;en&quot;, &quot;&quot;); /** Useful constant for language. */ static public final Locale FRENCH = createConstant(&quot;fr&quot;, &quot;&quot;); /** Useful constant for language. */ static public final Locale GERMAN = createConstant(&quot;de&quot;, &quot;&quot;); /** Useful constant for language. */ static public final Locale ITALIAN = createConstant(&quot;it&quot;, &quot;&quot;); /** Useful constant for language. */ static public final Locale JAPANESE = createConstant(&quot;ja&quot;, &quot;&quot;); /** Useful constant for language. */ static public final Locale KOREAN = createConstant(&quot;ko&quot;, &quot;&quot;); /** Useful constant for language. */ static public final Locale CHINESE = createConstant(&quot;zh&quot;, &quot;&quot;); 12345678 //从Locale的构造方法中，也看出Locale中可包含语言（language）,国家(country),变体（variant） public Locale(String language, String country, String variant) &#123; if (language== null || country == null || variant == null) &#123; throw new NullPointerException(); &#125; baseLocale = BaseLocale.getInstance(convertOldISOCodes(language), &quot;&quot;, country, variant); localeExtensions = getCompatibilityExtensions(language, &quot;&quot;, country, variant);&#125; LocaleContext Spring中存储用户地域信息的上下文，LocaleContext中采用的是ThreadLocal变量来存储信息，线程隔离，这样就可以让locale参数从各层的方法参数中移除。我们在写业务代码时也尽量不要将Locale参数通过方法参数中传入，利用LocaleContext可以让代码显得更优雅点。此外Spring也提供一些LocaleChangeInterceptor 的实现，并不需要我们自己维护这些信息。 AcceptHeaderLocaleResolver 通过Accept-Language加载locale信息 CookieLocaleResolver 通过Cookie加载locale信息 FixedLocaleResolver 全局静态的，返回一个默认的Locale SessionLocaleResolver 通过SessionLocaleResolver加载locale信息 MessageSource 对于多语言的翻译，无非就是先定义一些key，然后根据给这些key配置各种locale对应的文本。而Spring中的MessageSource就是维护这些配置信息的组件，Spring中有ResourceBundleMessageSource 和 ReloadableResourceBundleMessageSource的实现，可以将多语言的配置在{basename}_{locale}.properties文件中。ResourceBundleMessageSource 每次修改配置需要重启服务才能生效，而ReloadableResourceBundleMessageSource可以热更新。 当然我们也可以自己实现一个MessageSource从DB或者从其他存储源加载配置，后面我将单独写一篇文章介绍如何自定义MessageSource进行拓展的。 多语言的处理流程","categories":[{"name":"架构总结","slug":"架构总结","permalink":"http://liaojiacan.me/categories/架构总结/"}],"tags":[{"name":"多语言","slug":"多语言","permalink":"http://liaojiacan.me/tags/多语言/"},{"name":"i18n","slug":"i18n","permalink":"http://liaojiacan.me/tags/i18n/"}]},{"title":"谈谈多语言设计（一）之客户端多语言与服务端多语言","slug":"谈谈多语言设计（一）之-客户端多语言与服务端多语言","date":"2018-03-07T03:56:00.000Z","updated":"2019-05-22T05:43:18.861Z","comments":true,"path":"2018/03/07/谈谈多语言设计（一）之-客户端多语言与服务端多语言/","link":"","permalink":"http://liaojiacan.me/2018/03/07/谈谈多语言设计（一）之-客户端多语言与服务端多语言/","excerpt":"","text":"2017年的一个风口就是移动互联网的出海，很多公司都战略性地在海外做起了互联网商业化，最近也是接触了一些国际的项目，用户散落在各个国家地区，刚开始大部分是由客户端进行多语言的适配，后来由于产品觉得灵活性太差，于是把部分功能移到服务端来实现，但是发现无论是客户端实现还是服务端实现都存在一些弊端。 我们先思考一下以下几个问题： 完全由服务端实现多语言有什么弊端? 对于大部分应用场景，多语言都可以在服务端实现，但有一种情况不适合使用服务端多语言。比如目标用户语言非唯一，IM群发，推送等业务场景，虽然大部分消息推送服务可以按用户属性或者标签进行推送，服务端可以分开推送来实现，但是对于用户群推地域很分散的应用显然不是很合适。 完全由客户端实现多语言由什么弊端？ 大部分情况下都是采用的客户端写多语言配置进行适配，不管是android 还是iOS 还是常见的前端框架都是支持i18n的配置。这种方式有个缺点就是灵活性比较差，修改文案必须发包。 对于移动应用多语言是该客户端做还是服务端做，如何找到一个平衡点？ 无论是客户端多语言还是服务端多语言都有各自的优劣，主要还是看应用场景。 个人认为对于移动应用的多语言，应该把两者结合起来使用。对于UI等相对固定的部分采用客户端多语言。对于变动比较大的部分，采用服务端进行多语言的处理，比如名称，描述这些可能会根据运营场景进行调整的信息。 为什么不采用服务端生成配置客户端加载配置的方式？ 这种方式是一种比较灵活的方式，但是对于协议的定义不是很友好（key必须唯一，势必导致接口的返回体变大），而且无论是客户端还是服务端解析也比较耗资源，接口可读性比较差。而且把业务跟多语言的耦合太重，无论是客户端和服务端在编码的时候应该把多语言与业务解构，即便没有多语言部分也不影响业务的执行。 如果将客户端多语言和服务端多语言结合使用，怎么规范比较适合？ 简单来说，就是以下几点: UI部分由客户端实现多语言 所有客户端主动向服务端拉取的由服务端实现 对于群发等应用场景，由服务端生成语言包，客户端在一定时机拉取并加载到应用中。","categories":[{"name":"架构总结","slug":"架构总结","permalink":"http://liaojiacan.me/categories/架构总结/"}],"tags":[{"name":"多语言","slug":"多语言","permalink":"http://liaojiacan.me/tags/多语言/"},{"name":"i18n","slug":"i18n","permalink":"http://liaojiacan.me/tags/i18n/"}]},{"title":"Source Tree 配置支持gerrit review","slug":"Source-Tree-配置支持gerrit-review","date":"2018-02-07T07:34:45.000Z","updated":"2019-05-22T05:43:18.859Z","comments":true,"path":"2018/02/07/Source-Tree-配置支持gerrit-review/","link":"","permalink":"http://liaojiacan.me/2018/02/07/Source-Tree-配置支持gerrit-review/","excerpt":"","text":"source tree 可以支持自定义菜单，我们自定义一个菜单，来实现gerrit push review操作 1.先创建一个脚本，这里我叫 git_push_gerrit.sh 123456#!/bin/bash# Push for gerrit review# Created by Liaojiacan on 6.2.2017.# Copyright (c) 2018 liaojiacan. All rights reserved.branch=$(git symbolic-ref --short -q HEAD)git push origin HEAD:refs/for/$branch 2.在SourceTree创建一个自定义操作","categories":[],"tags":[]},{"title":"抽奖业务设计","slug":"抽奖业务设计","date":"2017-12-16T08:12:00.000Z","updated":"2019-05-22T05:43:18.861Z","comments":true,"path":"2017/12/16/抽奖业务设计/","link":"","permalink":"http://liaojiacan.me/2017/12/16/抽奖业务设计/","excerpt":"","text":"抽奖是一个比较常见的业务，关于抽奖的算法也有很多种实现，下面介绍一种比较容易实现的方式。 1.根据中奖概率的精确度，取一个权重的基线作为（概率-&gt;概率区间）的放大因子。比如，概率的精确度是到万分位，则基线取10000，保证转换后的区间&gt;=1 2.将奖品按对应的中奖概率*基线 转换成权重区间，并记录权重的上限值。 3.在权重上限值的范围内产生一个随机数，利用迭代查找或者二分查找算法找到对应的权重区间，即可获取到对应的奖品。 假设奖品的配置如下： 123456&quot;一等奖&quot;:0.01&quot;二等奖&quot;:0.1&quot;三等奖&quot;:0.15&quot;四等奖&quot;:0.2&quot;五等奖&quot;:0.25&quot;六等奖&quot;:0.29 概率转换到权重区间（放大10000倍）： 123456一等奖:[0.000000,100.000000)二等奖:[100.000000,1100.000000)三等奖:[1100.000000,2600.000000)四等奖:[2600.000000,4100.000000)五等奖:[4100.000000,6100.000000)六等奖:[6100.000000,8600.000000) 算法实现：Github 123456789101112131415161718192021222324252627282930313233343536373839public class LotteryPrize &#123; private String id; private String name; private double possibility; public LotteryPrize() &#123; &#125; public LotteryPrize(String id, String name, double possibility) &#123; this.id = id; this.name = name; this.possibility = possibility; &#125; public String getId() &#123; return id; &#125; public void setId(String id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public double getPossibility() &#123; return possibility; &#125; public void setPossibility(double possibility) &#123; this.possibility = possibility; &#125;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061public class LotteryMachine &#123; private PossibilityArea[] table; private int bound = 1; private Random random = new Random(); private static final int BASE_WEIGHT = 10000; class PossibilityArea&#123; private LotteryPrize prize; private double start; private double end; public PossibilityArea(LotteryPrize prize, double start, double end) &#123; this.prize = prize; this.start = start; this.end = end; System.out.printf(&quot;%s:[%f,%f)\\n&quot;,prize.getName(),start,end); &#125; &#125; public LotteryMachine(List&lt;LotteryPrize&gt; prizes) &#123; table = new PossibilityArea[prizes.size()]; double start = 0; for(int i=0;i&lt;prizes.size();i++)&#123; LotteryPrize prize = prizes.get(i); double weight = prize.getPossibility() * BASE_WEIGHT; Double end = start + weight; PossibilityArea area = new PossibilityArea(prize,start,end); table[i]= area; bound = end.intValue(); start=end; &#125; &#125; private LotteryPrize binarySearch(int rnd)&#123; int low = 0; int hight = table.length; while (low&lt;hight)&#123; int mid = (low + hight) / 2; PossibilityArea area = table[mid]; if(area.start&lt;=rnd &amp;&amp; area.end&gt;rnd)&#123; return area.prize; &#125; if(area.end&lt;=rnd)&#123; low=mid+1; &#125; if(area.start&gt;rnd)&#123; hight=mid; &#125; &#125; return null; &#125; public LotteryPrize go()&#123; int rnd = random.nextInt(bound); return binarySearch(rnd); &#125;&#125;","categories":[{"name":"java","slug":"java","permalink":"http://liaojiacan.me/categories/java/"}],"tags":[{"name":"业务开发","slug":"业务开发","permalink":"http://liaojiacan.me/tags/业务开发/"}]},{"title":"Java根据指定的country和lang格式化时间","slug":"Java根据指定的country和lang格式化时间","date":"2017-10-16T13:18:00.000Z","updated":"2019-05-22T05:43:18.858Z","comments":true,"path":"2017/10/16/Java根据指定的country和lang格式化时间/","link":"","permalink":"http://liaojiacan.me/2017/10/16/Java根据指定的country和lang格式化时间/","excerpt":"","text":"服务端或者客户端在做一些多语言的时候可能会涉及到时间戳的格式化，不同的语言或者不同的国家的时间的表达格式可能不同。 12345public String formatDate(Date date,String lang,String country)&#123; Locale locale = new Locale(lang,country,&quot;&quot;); DateFormat dateFormat = DateFormat.getDateTimeInstance(DateFormat.DEFAULT,DateFormat.MEDIUM,locale); return dateFormat.format(date);&#125;","categories":[],"tags":[{"name":"java","slug":"java","permalink":"http://liaojiacan.me/tags/java/"},{"name":"业务开发","slug":"业务开发","permalink":"http://liaojiacan.me/tags/业务开发/"}]},{"title":"Iedis破解思路","slug":"Iedis破解思路","date":"2017-10-12T07:01:00.000Z","updated":"2019-05-22T05:43:18.856Z","comments":true,"path":"2017/10/12/Iedis破解思路/","link":"","permalink":"http://liaojiacan.me/2017/10/12/Iedis破解思路/","excerpt":"","text":"Iedis是IDEA上的一个收费redis插件，java编写的，既然是java写的，收费这些自然是很容易绕过的。由于Java太容易被反编译，作者还是做了些代码混淆和字符串加密。 利用JD-GUI反编译出来的代码片段 可以看出类名和字符串都被混淆和加密了，从代码上很难去定位和分析他的注册流程。 1234567891011121314151617181920212223242526272829303132package com.seventh7.widget.iedis.config;import com.intellij.icons.AllIcons.General;import com.intellij.openapi.actionSystem.AnActionEvent;import com.intellij.openapi.ui.Messages;class i extends e&#123; private static final String[] ib; private static final String[] jb; i(n paramn) &#123; super(a(20539, 52876), a(20539, 52876), AllIcons.General.Remove, a(20537, 55341), paramn); &#125; void a(AnActionEvent paramAnActionEvent, P paramP) &#123; String str1 = String.format(a(20538, 25199), new Object[] &#123; paramP.f() &#125;); String str2 = a(20536, 20012); try &#123; if (Messages.showOkCancelDialog(a(), str1, str2, Messages.getQuestionIcon()) == 0) &#123; com.seventh7.widget.iedis.d.e.a().a(a(), paramP.b()); &#125; &#125; catch (RuntimeException localRuntimeException) &#123; throw d(localRuntimeException); &#125; &#125; 破解的2个思路 还原代码中的所有加密字符串，根据字符串的内定位到相关的代码，利用javassist修改class文件，将文件替换掉原来的文件 逆向出他的认证算法，然后做个注册机之类的。iedis是采用服务器认证的，每次启动都要去服务器查询激活，所以注册机不适合。但是我们可以本地架设一个认证服务。 架设认证服务器还是比较简单的，下面还是主要研究一下第一种思路。 还原字符串 从那些混淆的代码去定位软件的运行逻辑很难下手，但是我们可以换个思路，将软件运行过程中字符串都打印出来，这样我们基本上就可以得到一份软件的运行日志，对java程序进行运行时插入语句看似很麻烦，其实JVM默认就支持javaagent，写个javaagent即可达到效果，javaagent的使用可以参考《javaagent-的使用》 编写javaagent程序 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556/** * 给iedis的加密字符串函数 插入打印代码 */public class IedisTransformer implements ClassFileTransformer &#123; private final static String IDEA_LIB=&quot;/Applications/IntelliJ IDEA.app/Contents/lib/*&quot;; private final static String IDEIS_LIB=&quot;/Users/liaojiacan/Library/Application Support/IntelliJIdea2017.2/Iedis/lib/*&quot;; public IedisTransformer() &#123; try &#123; ClassPool.getDefault().appendClassPath(IDEA_LIB); ClassPool.getDefault().appendClassPath(IDEIS_LIB); &#125; catch (NotFoundException e) &#123; e.printStackTrace(); &#125; &#125; @Override public byte[] transform(ClassLoader loader, String className, Class&lt;?&gt; classBeingRedefined, ProtectionDomain protectionDomain, byte[] classfileBuffer) throws IllegalClassFormatException &#123; if(className.startsWith(&quot;com/seventh7/widget/iedis&quot;))&#123; try &#123; CtClass clazz = ClassPool.getDefault().makeClass(new ByteArrayInputStream(classfileBuffer)); CtMethod[] methods = clazz.getDeclaredMethods(); CtClass string = ClassPool.getDefault().getCtClass(String.class.getName()); for(CtMethod method :methods)&#123; if(method.getLongName().startsWith(&quot;com.seventh7.widget.iedis.a.p.f&quot;))&#123; System.out.println(&quot;Inject :: SUCCESS!&quot;); method.insertBefore(&quot;if(true)&#123;return true;&#125; &quot;); continue; &#125; if(method.getReturnType().equals(string))&#123; String name = method.getLongName(); System.out.println(&quot;transform the iedis method:&quot;+name); method.insertAfter(&quot;System.out.println(\\&quot;--------------------\\&quot;);&quot; + &quot; System.out.println(\\&quot;&quot;+name+&quot;\\&quot;); &quot; + &quot; System.out.println(java.util.Arrays.toString($args)); &quot; + &quot; System.out.println(\\&quot;return:\\&quot;+$_);&quot;); &#125; &#125; return clazz.toBytecode(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; catch (NotFoundException e) &#123; e.printStackTrace(); &#125; catch (CannotCompileException e) &#123; e.printStackTrace(); &#125; &#125; return null; &#125;&#125; 修改System.out，把所有的print打印到我们指定的文件中 /tmp/system.out 12345678910111213141516171819202122232425262728public class Main &#123; public static void premain(String agentOps, Instrumentation inst) &#123; PrintStream out = null; try &#123; out = new PrintStream(&quot;/tmp/system.out&quot;); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; System.setOut(out); System.setErr(out); if (&quot;iedis&quot;.equals(agentOps))&#123; inst.addTransformer(new IedisTransformer()); &#125;else if(&quot;injectPrint&quot;.equals(agentOps)) &#123; inst.addTransformer(new InjectPrintTransformer()); &#125;else &#123; inst.addTransformer(new SimpleTransformer()); &#125; &#125; public static void main(String[] args) &#123; System.out.println(helloWorld()); &#125; public static String helloWorld()&#123; return &quot;This is a javaagent!&quot;; &#125;&#125; 配置idea启动配置，加入我们的javaagent 12345678910111213141516171819#修改idea.vmoptions文件加入下面一行配置-javaagent:/Users/liaojiacan/Workspace/tools/decomplie/javaagent/javaagent-1.0-SNAPSHOT.jar=iedis-Xms128m-Xmx750m-XX:ReservedCodeCacheSize=240m-XX:+UseCompressedOops-Dfile.encoding=UTF-8-XX:+UseConcMarkSweepGC-XX:SoftRefLRUPolicyMSPerMB=50-ea-Dsun.io.useCanonCaches=false-Djava.net.preferIPv4Stack=true-XX:+HeapDumpOnOutOfMemoryError-XX:-OmitStackTraceInFastThrow-Xverify:none-XX:ErrorFile=$USER_HOME/java_error_in_idea_%p.log-XX:HeapDumpPath=$USER_HOME/java_error_in_idea.hprof-Xbootclasspath/a:../lib/boot.jar 启动Idea 后我们可以在/tmp/system.out中可以看到这些关键的日志 123456789101112131415161718192021222324252627282930--------------------com.seventh7.widget.iedis.L.a(java.lang.String)return:&#123;&quot;trailing&quot;:true,&quot;daysLeft&quot;:9,&quot;popup&quot;:true,&quot;activated&quot;:false&#125;--------------------com.seventh7.widget.iedis.B.a()return:186b474e0ffffffb70ffffff96680ffffffc0240ffffff89456b0fffffffa320ffffffa70ffffff92--------------------com.seventh7.widget.iedis.x.a(byte[])return:MTg2YjQ3NGUwZmZmZmZmYjcwZmZmZmZmOTY2ODBmZmZmZmZjMDI0MGZmZmZmZjg5NDU2YjBmZmZmZmZmYTMyMGZmZmZmZmE3MGZmZmZmZjkyOjI=--------------------com.seventh7.widget.iedis.L.a(java.lang.String)return:&#123;&quot;trailing&quot;:true,&quot;daysLeft&quot;:9,&quot;popup&quot;:true,&quot;activated&quot;:false&#125;--------------------com.seventh7.widget.iedis.L.a(java.lang.String)[https://www.codesmagic.com/q2?t=MTg2YjQ3NGUwZmZmZmZmYjcwZmZmZmZmOTY2ODBmZmZmZmZjMDI0MGZmZmZmZjg5NDU2YjBmZmZmZmZmYTMyMGZmZmZmZmE3MGZmZmZmZjkyOjI=]return:&#123;&quot;trailing&quot;:true,&quot;daysLeft&quot;:9,&quot;popup&quot;:true,&quot;activated&quot;:false&#125;--------------------com.seventh7.widget.iedis.a.p.b(int,int)[-13938, -6118]return:trailing--------------------com.seventh7.widget.iedis.a.p.b(int,int)[-13937, -25088]return:daysLeft--------------------com.seventh7.widget.iedis.a.p.b(int,int)[-13939, 7216]return:popup 从上面的日志可以看出一些关键点： https://www.codesmagic.com/q2?t= 是注册的服务器 com.seventh7.widget.iedis.a.o 这个类是很关键的类 认证服务器返回的认证结果为 {“trailing”:true,“daysLeft”:9,“popup”:true,“activated”:false} 查看反编译的代码，可以看出这个类是一个抽象类，他的唯一子类是com.seventh7.widget.iedis.a.p，根据外面获取到的运行日志，大概可以推断出 f这个方法是认证的方法。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495package com.seventh7.widget.iedis.a;import com.seventh7.widget.iedis.b.d.a;import java.util.Map;import java.io.IOException;import com.seventh7.widget.iedis.L;class p extends o&#123; private static final String[] kb; private static final String[] lb; //基本上可以推断出 这个就是认证的方法，最直接的方法就是直接return true @Override protected boolean f() throws IOException &#123; //this.d() 是调用https://www.codesmagic.com/q2去注册的 //Map的返回值&#123;&quot;trailing&quot;:true,&quot;daysLeft&quot;:9,&quot;popup&quot;:true,&quot;activated&quot;:false&#125; final Map d = this.d(); //trailing final boolean booleanValue = L.a(d, b(-13938, -6118)); //this.d()执行后的异常信息。 final a[] b = av.b(); //daysLeft final int b2 = L.b(d, b(-13937, -25088)); //popup final boolean booleanValue2 = L.a(d, b(-13939, 7216)); boolean booleanValue3 = false; Label_0104: &#123; Label_0074: &#123; boolean b3; try &#123; b3 = (booleanValue3 = booleanValue); if (b != null) &#123; break Label_0104; &#125; if (b3) &#123; break Label_0074; &#125; break Label_0074; &#125; catch (IOException ex) &#123; throw b(ex); &#125; try &#123; if (b3) &#123; this.a(b2, booleanValue2); return false; &#125; &#125; catch (IOException ex2) &#123; throw b(ex2); &#125; &#125; //actived booleanValue3 = L.a(d, b(-13940, 8507)); &#125; final boolean b4 = booleanValue3; //如果已经过了试用，就检测激活 Label_0122: &#123; boolean b5; try &#123; final boolean b6; b5 = (b6 = b4); // b = av.b() if (b != null) &#123; return b6; &#125; if (!b5) &#123; break Label_0122; &#125; return true; &#125; catch (IOException ex3) &#123; throw b(ex3); &#125; try &#123; if (!b5) &#123; this.c(); return false; &#125; &#125; catch (IOException ex4) &#123; throw b(ex4); &#125; &#125; return true; &#125; private static IOException b(final IOException ex) &#123; return ex; &#125; &#125; 从上面的分享结果可以看出，有两种破解思路 方法一 修改 com.seventh7.widget.iedis.a.p.f 永远return true 方法二 搭建一个认证服务器，本地替换host，认证服务器返回的结果为 1&#123; &quot;trailing&quot;: false, &quot;popup&quot;: true, &quot;activated&quot;: true, &quot;daysLeft&quot;: 0 &#125; 方法一的实现 123456789101112131415161718192021222324252627282930313233343536public class IedisCracker &#123; private final static String IDEA_LIB=&quot;/Applications/IntelliJ IDEA.app/Contents/lib/*&quot;; private final static String IDEIS_LIB=&quot;/Users/liaojiacan/Library/Application Support/IntelliJIdea2017.2/Iedis/lib/*&quot;; public static void main(String[] args) &#123; try &#123; ClassPool.getDefault().appendClassPath(IDEA_LIB); ClassPool.getDefault().appendClassPath(IDEIS_LIB); CtClass clazz = ClassPool.getDefault().getCtClass(&quot;com.seventh7.widget.iedis.a.p&quot;); CtMethod[] mds = clazz.getDeclaredMethods(); for(CtMethod method : mds)&#123; if(method.getLongName().startsWith(&quot;com.seventh7.widget.iedis.a.p.f&quot;))&#123; System.out.println(&quot;Inject :: SUCCESS!&quot;); try &#123; method.insertBefore(&quot;if(true)&#123;return true;&#125; &quot;); &#125; catch (CannotCompileException e) &#123; e.printStackTrace(); &#125; continue; &#125; &#125; clazz.writeFile(&quot;/tmp/p.class&quot;); &#125; catch (NotFoundException e) &#123; e.printStackTrace(); &#125; catch (CannotCompileException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125;","categories":[{"name":"逆向","slug":"逆向","permalink":"http://liaojiacan.me/categories/逆向/"}],"tags":[{"name":"java逆向","slug":"java逆向","permalink":"http://liaojiacan.me/tags/java逆向/"}]},{"title":"proto变量类型与java类型对照表","slug":"proto变量类型与java类型对照表","date":"2017-10-11T02:53:00.000Z","updated":"2019-05-22T05:43:18.860Z","comments":true,"path":"2017/10/11/proto变量类型与java类型对照表/","link":"","permalink":"http://liaojiacan.me/2017/10/11/proto变量类型与java类型对照表/","excerpt":"","text":"proto type java type double double float float int32 int int64 long uint32 int uint64 long sint32 int sint64 long fixed32 int fixed64 long sfixed32 int sfixed32 long bool boolean string string bytes ByteString","categories":[],"tags":[{"name":"Protobuf","slug":"Protobuf","permalink":"http://liaojiacan.me/tags/Protobuf/"},{"name":"rpc","slug":"rpc","permalink":"http://liaojiacan.me/tags/rpc/"}]},{"title":"proto文件","slug":"proto文件","date":"2017-10-10T11:52:00.000Z","updated":"2019-05-22T05:43:18.860Z","comments":true,"path":"2017/10/10/proto文件/","link":"","permalink":"http://liaojiacan.me/2017/10/10/proto文件/","excerpt":"","text":"proto文件是Proto buffers的描述文件 syntax 指定pd编译器的版本，可以设置proto2或者proto3 message 类似java中的class关键字，在PB这里叫消息体 service 服务声明 修饰符 required 非空，必须存在 optional 可选 repeated 可重复出现，类似集合的概念吧 更多介绍参考官方文档，Protocal Buffers 123456789101112131415syntax = &quot;proto3&quot;;service SearchService&#123; rpc search(SearchRequest) returns (SearchResponse) &#123;&#125;&#125;message SearchRequest &#123; required string query = 1; optional int32 page_number = 2; optional int32 result_per_page = 3;&#125;message SearchResponse &#123; string result = 1;&#125;","categories":[],"tags":[{"name":"Protobuf","slug":"Protobuf","permalink":"http://liaojiacan.me/tags/Protobuf/"},{"name":"rpc","slug":"rpc","permalink":"http://liaojiacan.me/tags/rpc/"}]},{"title":"javaagent 的使用","slug":"javaagent-的使用","date":"2017-10-10T03:40:00.000Z","updated":"2019-05-22T05:43:18.859Z","comments":true,"path":"2017/10/10/javaagent-的使用/","link":"","permalink":"http://liaojiacan.me/2017/10/10/javaagent-的使用/","excerpt":"","text":"javaagent 是类似一个JVM的插件，利用JVM提供的Instrumentation API实现获取或者修改加载到JVM中的类字节码。 编写一个javagent的jar的方式如下： 1.实现一个ClassFileTransformer 12345678910public class SimpleTransformer implements ClassFileTransformer &#123; @Override public byte[] transform(ClassLoader loader, String className, Class&lt;?&gt; classBeingRedefined, ProtectionDomain protectionDomain, byte[] classfileBuffer) throws IllegalClassFormatException &#123; System.out.println(className); System.out.println(protectionDomain.toString()); return new byte[0]; &#125;&#125; 2.实现一个Premain-Class 12345678910public class Main &#123; public static void premain(String agentOps, Instrumentation inst) &#123; inst.addTransformer(new SimpleTransformer()); &#125; public static void main(String[] args) &#123; System.out.println(&quot;This is a javaagent!&quot;); &#125;&#125; 3.MANIFEST.MF配置 12345Manifest-Version: 1.0Premain-Class: com.github.liaojiacan.MainCan-Redefine-Classes: trueCan-Retransform-Classes: trueCan-Set-Native-Method-Prefix: true 4.运行命令 1java -javaagent:agent.jar -jar app.jar 代码和assembly的打包配置可以参考，github","categories":[{"name":"逆向","slug":"逆向","permalink":"http://liaojiacan.me/categories/逆向/"}],"tags":[{"name":"java逆向","slug":"java逆向","permalink":"http://liaojiacan.me/tags/java逆向/"},{"name":"java","slug":"java","permalink":"http://liaojiacan.me/tags/java/"}]},{"title":"Linux shell命令:cut命令","slug":"Linux Shell--cut命令","date":"2017-02-23T08:45:44.000Z","updated":"2019-05-22T05:43:18.858Z","comments":true,"path":"2017/02/23/Linux Shell--cut命令/","link":"","permalink":"http://liaojiacan.me/2017/02/23/Linux Shell--cut命令/","excerpt":"","text":"简介 将一段数据经过分析，取出我们想要的 1234cut -- cut out selected portions of each line of a file SYNOPSIScut -b list [-n] [file ...]cut -c list [file ...]cut -f list [-d delim] [-s] [file ...] -b ：以字节为单位进行分割。这些字节位置将忽略多字节字符边界，除非也指定了 -n 标志。 -c ：以字符为单位进行分割。 -d ：自定义分隔符，默认为制表符。 -f ：与-d一起使用，指定显示哪个区域。 -n ：取消分割多字节字符。仅和 -b 标志一起使用。如果字符的最后一个字节落在由 -b 标志的 List 参数指示的范围之内，该字符将被写出；否则，该字符将被排除。 1who | cut -d 3-5 #截取 3-5列的内容 1who | cut -c 3-5 #截取 3-5列的内容 中文字符 1cat /etc/passwd|head -n 5|cut -d : -f -2 # 设置分隔符为：","categories":[{"name":"linux","slug":"linux","permalink":"http://liaojiacan.me/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://liaojiacan.me/tags/linux/"},{"name":"shell","slug":"shell","permalink":"http://liaojiacan.me/tags/shell/"}]}]}